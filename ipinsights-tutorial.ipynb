{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to the Amazon SageMaker IP Insights Algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This notebook's CI test result for us-west-2 is as follows. CI test results in other regions can be found at the end of the notebook. \n",
    "\n",
    "![This us-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-2/introduction_to_amazon_algorithms|ipinsights_login|ipinsights-tutorial.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unsupervised anomaly detection for susicipous IP addresses\n",
    "-------\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Setup](#Setup)\n",
    "3. [Training](#Training)\n",
    "4. [Inference](#Inference)\n",
    "5. [Epilogue](#Epilogue)\n",
    "\n",
    "## Introduction\n",
    "-------\n",
    "\n",
    "The Amazon SageMaker IP Insights algorithm uses statistical modeling and neural networks to capture associations between online resources (such as account IDs or hostnames) and IPv4 addresses. Under the hood, it learns vector representations for online resources and IP addresses. This essentially means that if the vector representing an IP address and an online resource are close together, then it is likey for that IP address to access that online resource, even if it has never accessed it before.\n",
    "\n",
    "In this notebook, we use the Amazon SageMaker IP Insights algorithm to train a model on synthetic data. We then use this model to perform inference on the data and show how to discover anomalies. After running this notebook, you should be able to:\n",
    "\n",
    "- obtain, transform, and store data for use in Amazon SageMaker,\n",
    "- create an AWS SageMaker training job to produce an IP Insights model,\n",
    "- use the model to perform inference with an Amazon SageMaker endpoint.\n",
    "\n",
    "If you would like to know more, please check out the [SageMaker IP Inisghts Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/ip-insights.html). \n",
    "\n",
    "## Setup\n",
    "------\n",
    "*This notebook was tested in Amazon SageMaker Studio on a ml.t3.medium instance with Python 3 (Data Science) kernel.*\n",
    "\n",
    "Our first step is to setup our AWS credentials so that AWS SageMaker can store and access training data and model artifacts.\n",
    "\n",
    "### Select Amazon S3 Bucket\n",
    "We first need to specify the locations where we will store our training data and trained model artifacts. ***This is the only cell of this notebook that you will need to edit.*** In particular, we need the following data:\n",
    "\n",
    "- `bucket` - An S3 bucket accessible by this account.\n",
    "- `prefix` - The location in the bucket where this notebook's input and output data will be stored. (The default value is sufficient.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.241.0)\n",
      "Collecting sagemaker\n",
      "  Downloading sagemaker-2.242.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (23.2.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.35.75 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (1.37.7)\n",
      "Requirement already satisfied: cloudpickle>=2.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (3.1.1)\n",
      "Requirement already satisfied: docker in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (7.1.0)\n",
      "Requirement already satisfied: fastapi in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (0.115.11)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (6.11.0)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (4.23.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (1.26.4)\n",
      "Requirement already satisfied: omegaconf<=2.3,>=2.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (2.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (21.3)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (1.5.3)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (0.3.3)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (4.3.6)\n",
      "Requirement already satisfied: protobuf<6.0,>=3.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (5.29.3)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (6.1.1)\n",
      "Requirement already satisfied: pyyaml~=6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (2.32.3)\n",
      "Requirement already satisfied: sagemaker-core<2.0.0,>=1.0.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (1.0.25)\n",
      "Requirement already satisfied: schema in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (0.7.7)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: tblib<4,>=1.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (3.0.0)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (4.67.1)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (2.3.0)\n",
      "Requirement already satisfied: uvicorn in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (0.34.0)\n",
      "Requirement already satisfied: botocore<1.38.0,>=1.37.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0,>=1.35.75->sagemaker) (1.37.7)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0,>=1.35.75->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0,>=1.35.75->sagemaker) (0.11.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.21.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from omegaconf<=2.3,>=2.2->sagemaker) (4.9.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=20.0->sagemaker) (3.2.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker) (2.10.6)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker) (13.9.4)\n",
      "Requirement already satisfied: mock<5.0,>4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.17->sagemaker) (4.0.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema->sagemaker) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.22.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->sagemaker) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->sagemaker) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->sagemaker) (2025.1.31)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from fastapi->sagemaker) (0.46.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from fastapi->sagemaker) (4.12.2)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-pasta->sagemaker) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->sagemaker) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->sagemaker) (2025.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker) (1.7.6.9)\n",
      "Requirement already satisfied: dill>=0.3.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.9)\n",
      "Requirement already satisfied: pox>=0.3.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.5)\n",
      "Requirement already satisfied: multiprocess>=0.70.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker) (0.70.17)\n",
      "Requirement already satisfied: click>=7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from uvicorn->sagemaker) (8.1.8)\n",
      "Requirement already satisfied: h11>=0.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from uvicorn->sagemaker) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (2.27.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (2.19.1)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from starlette<0.47.0,>=0.40.0->fastapi->sagemaker) (4.8.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi->sagemaker) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi->sagemaker) (1.3.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.17->sagemaker) (0.1.2)\n",
      "Downloading sagemaker-2.242.0-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Installing collected packages: sagemaker\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.241.0\n",
      "    Uninstalling sagemaker-2.241.0:\n",
      "      Successfully uninstalled sagemaker-2.241.0\n",
      "Successfully installed sagemaker-2.242.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sagemaker --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03/17/25 18:33:22] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03/17/25 18:33:22]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=870979;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=944523;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03/17/25 18:33:26] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03/17/25 18:33:26]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=880858;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=239139;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03/17/25 18:33:27] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03/17/25 18:33:27]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=820969;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256410;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=593258;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=41588;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training input/output will be stored in: s3://sagemaker-us-east-2-160885266928/sagemaker/ipinsights-tutorial\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "import os\n",
    "import sagemaker\n",
    "\n",
    "\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "prefix = \"sagemaker/ipinsights-tutorial\"\n",
    "execution_role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# check if the bucket exists\n",
    "try:\n",
    "    boto3.Session().client(\"s3\").head_bucket(Bucket=bucket)\n",
    "except botocore.exceptions.ParamValidationError as e:\n",
    "    print(\n",
    "        \"Hey! You either forgot to specify your S3 bucket or you gave your bucket an invalid name!\"\n",
    "    )\n",
    "except botocore.exceptions.ClientError as e:\n",
    "    if e.response[\"Error\"][\"Code\"] == \"403\":\n",
    "        print(f\"Hey! You don't have permission to access the bucket, {bucket}.\")\n",
    "    elif e.response[\"Error\"][\"Code\"] == \"404\":\n",
    "        print(f\"Hey! Your bucket, {bucket}, doesn't exist!\")\n",
    "    else:\n",
    "        raise\n",
    "else:\n",
    "    print(f\"Training input/output will be stored in: s3://{bucket}/{prefix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we download the modules necessary for synthetic data generation they do not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03/17/25 18:33:33] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03/17/25 18:33:33]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=573863;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=112374;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from os import path\n",
    "\n",
    "tools_bucket = f\"jumpstart-cache-prod-{region}\"  # Bucket containing the data generation module.\n",
    "tools_prefix = \"1p-algorithms-assets/ip-insights\"  # Prefix for the data generation module\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "data_generation_file = \"generate_data.py\"  # Synthetic data generation module\n",
    "script_parameters_file = \"ip2asn-v4-u32.tsv.gz\"\n",
    "\n",
    "if not path.exists(data_generation_file):\n",
    "    s3.download_file(tools_bucket, f\"{tools_prefix}/{data_generation_file}\", data_generation_file)\n",
    "\n",
    "if not path.exists(script_parameters_file):\n",
    "    s3.download_file(\n",
    "        tools_bucket, f\"{tools_prefix}/{script_parameters_file}\", script_parameters_file\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Apache Web Server (\"httpd\") is the most popular web server used on the internet. And luckily for us, it logs all requests processed by the server - by default. If a web page requires HTTP authentication, the Apache Web Server will log the IP address and authenticated user name for each requested resource. \n",
    "\n",
    "The [access logs](https://httpd.apache.org/docs/2.4/logs.html) are typically on the server under the file `/var/log/httpd/access_log`. From the example log output below, we see which IP addresses each user has connected with:\n",
    "\n",
    "```\n",
    "192.168.1.100 - user1 [15/Oct/2018:18:58:32 +0000] \"GET /login_success?userId=1 HTTP/1.1\" 200 476 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36\"\n",
    "192.168.1.102 - user2 [15/Oct/2018:18:58:35 +0000] \"GET /login_success?userId=2 HTTP/1.1\" 200 - \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36\"\n",
    "...\n",
    "```\n",
    "\n",
    "If we want to train an algorithm to detect suspicious activity, this dataset is ideal for SageMaker IP Insights.\n",
    "\n",
    "First, we determine the resource we want to be analyzing (such as a login page or access to a protected file). Then, we construct a dataset containing the history of all past user interactions with the resource. We extract out each 'access event' from the log and store the corresponding user name and IP address in a headerless CSV file with two columns. The first column will contain the user identifier string, and the second will contain the IPv4 address in decimal-dot notation. \n",
    "\n",
    "```\n",
    "user1, 192.168.1.100\n",
    "user2, 193.168.1.102\n",
    "...\n",
    "```\n",
    "\n",
    "As a side note, the dataset should include all access events. That means some `<user_name, ip_address>` pairs will be repeated. \n",
    "\n",
    "#### User Activity Simulation\n",
    "For this example, we are going to simulate our own web-traffic logs. We mock up a toy website example and simulate users logging into the website from mobile devices. \n",
    "\n",
    "The details of the simulation are explained in the script [here](./generate_data.py). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ASN List: 827696 ASNs.\n",
      "Starting User Activity Simulation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:04<00:00, 155.00users/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished simulating web activity for 10000 users.\n",
      "204.239.159.114 - user_63 [09/Nov/2018:01:42:52 +0000] \"GET /login_success HTTP/1.1\" 200 476 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/555.33 (KHTML, like Gecko) Chrome/1.1.1111.100 Safari/555.355\"\n",
      "204.239.151.169 - user_63 [09/Nov/2018:22:57:30 +0000] \"GET /login_success HTTP/1.1\" 200 476 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/555.33 (KHTML, like Gecko) Chrome/1.1.1111.100 Safari/555.355\"\n",
      "203.32.246.152 - user_63 [13/Nov/2018:01:34:04 +0000] \"GET /login_success HTTP/1.1\" 200 476 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/555.33 (KHTML, like Gecko) Chrome/1.1.1111.100 Safari/555.355\"\n",
      "204.239.146.159 - user_63 [13/Nov/2018:22:23:37 +0000] \"GET /login_success HTTP/1.1\" 200 476 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/555.33 (KHTML, like Gecko) Chrome/1.1.1111.100 Safari/555.355\"\n",
      "203.32.223.77 - user_63 [05/Nov/2018:15:37:50 +0000] \"GET /login_success HTTP/1.1\" 200 476 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/555.33 (KHTML, like Gecko) Chrome/1.1.1111.100 Safari/555.355\"\n",
      "204.239.144.35 - user_63 [07/Nov/2018:08:41:45 +0000] \"GET /login_success HTTP/1.1\" 200 476 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/555.33 (KHTML, like Gecko) Chrome/1.1.1111.100 Safari/555.355\"\n",
      "204.239.179.19 - user_63 [07/Nov/2018:11:50:50 +0000] \"GET /login_success HTTP/1.1\" 200 476 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/555.33 (KHTML, like Gecko) Chrome/1.1.1111.100 Safari/555.355\"\n",
      "204.239.140.86 - user_63 [05/Nov/2018:22:29:56 +0000] \"GET /login_success HTTP/1.1\" 200 476 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/555.33 (KHTML, like Gecko) Chrome/1.1.1111.100 Safari/555.355\"\n",
      "203.32.184.15 - user_63 [11/Nov/2018:02:28:05 +0000] \"GET /login_success HTTP/1.1\" 200 476 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/555.33 (KHTML, like Gecko) Chrome/1.1.1111.100 Safari/555.355\"\n",
      "204.239.149.64 - user_63 [06/Nov/2018:09:21:59 +0000] \"GET /login_success HTTP/1.1\" 200 476 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/555.33 (KHTML, like Gecko) Chrome/1.1.1111.100 Safari/555.355\"\n"
     ]
    }
   ],
   "source": [
    "from generate_data import generate_dataset\n",
    "\n",
    "# We simulate traffic for 10,000 users. This should yield about 3 million log lines (~700 MB).\n",
    "NUM_USERS = 10000\n",
    "log_file = \"ipinsights_web_traffic.log\"\n",
    "generate_dataset(NUM_USERS, log_file)\n",
    "\n",
    "# Visualize a few log lines\n",
    "!head $log_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the dataset\n",
    "Now that we have our logs, we need to transform them into a format that IP Insights can use. As we mentioned above, we need to:\n",
    "1. Choose the resource which we want to analyze users' history for\n",
    "2. Extract our users' usage history of IP addresses\n",
    "3. In addition, we want to separate our dataset into a training and test set. This will allow us to check for overfitting by evaluating our model on 'unseen' login events.\n",
    "\n",
    "For the rest of the notebook, we assume that the Apache Access Logs are in the Common Log Format as defined by the [Apache documentation](https://httpd.apache.org/docs/2.4/logs.html#accesslog). We start with reading the logs into a Pandas DataFrame for easy data exploration and pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip_address</th>\n",
       "      <th>rcf_id</th>\n",
       "      <th>user</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>time_zone</th>\n",
       "      <th>request</th>\n",
       "      <th>status</th>\n",
       "      <th>size</th>\n",
       "      <th>referer</th>\n",
       "      <th>user_agent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>204.239.159.114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>user_63</td>\n",
       "      <td>[09/Nov/2018:01:42:52</td>\n",
       "      <td>+0000]</td>\n",
       "      <td>GET /login_success HTTP/1.1</td>\n",
       "      <td>200</td>\n",
       "      <td>476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>204.239.151.169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>user_63</td>\n",
       "      <td>[09/Nov/2018:22:57:30</td>\n",
       "      <td>+0000]</td>\n",
       "      <td>GET /login_success HTTP/1.1</td>\n",
       "      <td>200</td>\n",
       "      <td>476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>203.32.246.152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>user_63</td>\n",
       "      <td>[13/Nov/2018:01:34:04</td>\n",
       "      <td>+0000]</td>\n",
       "      <td>GET /login_success HTTP/1.1</td>\n",
       "      <td>200</td>\n",
       "      <td>476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>204.239.146.159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>user_63</td>\n",
       "      <td>[13/Nov/2018:22:23:37</td>\n",
       "      <td>+0000]</td>\n",
       "      <td>GET /login_success HTTP/1.1</td>\n",
       "      <td>200</td>\n",
       "      <td>476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>203.32.223.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>user_63</td>\n",
       "      <td>[05/Nov/2018:15:37:50</td>\n",
       "      <td>+0000]</td>\n",
       "      <td>GET /login_success HTTP/1.1</td>\n",
       "      <td>200</td>\n",
       "      <td>476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ip_address  rcf_id     user              timestamp time_zone  \\\n",
       "0  204.239.159.114     NaN  user_63  [09/Nov/2018:01:42:52    +0000]   \n",
       "1  204.239.151.169     NaN  user_63  [09/Nov/2018:22:57:30    +0000]   \n",
       "2   203.32.246.152     NaN  user_63  [13/Nov/2018:01:34:04    +0000]   \n",
       "3  204.239.146.159     NaN  user_63  [13/Nov/2018:22:23:37    +0000]   \n",
       "4    203.32.223.77     NaN  user_63  [05/Nov/2018:15:37:50    +0000]   \n",
       "\n",
       "                       request  status  size  referer  \\\n",
       "0  GET /login_success HTTP/1.1     200   476      NaN   \n",
       "1  GET /login_success HTTP/1.1     200   476      NaN   \n",
       "2  GET /login_success HTTP/1.1     200   476      NaN   \n",
       "3  GET /login_success HTTP/1.1     200   476      NaN   \n",
       "4  GET /login_success HTTP/1.1     200   476      NaN   \n",
       "\n",
       "                                          user_agent  \n",
       "0  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6...  \n",
       "1  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6...  \n",
       "2  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6...  \n",
       "3  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6...  \n",
       "4  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    log_file,\n",
    "    sep=\" \",\n",
    "    na_values=\"-\",\n",
    "    header=None,\n",
    "    names=[\n",
    "        \"ip_address\",\n",
    "        \"rcf_id\",\n",
    "        \"user\",\n",
    "        \"timestamp\",\n",
    "        \"time_zone\",\n",
    "        \"request\",\n",
    "        \"status\",\n",
    "        \"size\",\n",
    "        \"referer\",\n",
    "        \"user_agent\",\n",
    "    ],\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert the log timestamp strings into Python datetimes so that we can sort and compare the data more easily. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert time stamps to DateTime objects\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], format=\"[%d/%b/%Y:%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also verify the time zones of all of the time stamps. If the log contains more than one time zone, we would need to standardize the timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if they are all in the same timezone\n",
    "num_time_zones = len(df[\"time_zone\"].unique())\n",
    "num_time_zones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see above, there is only one value in the entire `time_zone` column. Therefore, all of the timestamps are in the same time zone, and we do not need to standardize them. We can skip the next cell and go to [1. Selecting a Resource](#1.-Select-Resource).\n",
    "\n",
    "If there is more than one time_zone in your dataset, then we parse the timezone offset and update the corresponding datetime object. \n",
    "\n",
    "**Note:** The next cell takes about 5-10 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "\n",
    "def apply_timezone(row):\n",
    "    tz = row[1]\n",
    "    tz_offset = int(tz[:3]) * 60  # Hour offset\n",
    "    tz_offset += int(tz[3:5])  # Minutes offset\n",
    "    return row[0].replace(tzinfo=pytz.FixedOffset(tz_offset))\n",
    "\n",
    "\n",
    "if num_time_zones > 1:\n",
    "    df[\"timestamp\"] = df[[\"timestamp\", \"time_zone\"]].apply(apply_timezone, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Select Resource\n",
    "Our goal is to train an IP Insights algorithm to analyze the history of user logins such that we can predict how suspicious a login event is. \n",
    "\n",
    "In our simulated web server, the server logs a `GET` request to the `/login_success` page everytime a user successfully logs in. We filter our Apache logs for `GET` requests for `/login_success`. We also filter for requests that have a `status_code == 200`, to ensure that the page request was well formed. \n",
    "\n",
    "**Note:** every web server handles logins differently. For your dataset, determine which resource you will need to be analyzing to correctly frame this problem. Depending on your usecase, you may need to do more data exploration and preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df[\"request\"].str.startswith(\"GET /login_success\")) & (df[\"status\"] == 200)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Extract Users and IP address\n",
    "Now that our DataFrame only includes log events for the resource we want to analyze, we extract the relevant fields to construct a IP Insights dataset.\n",
    "\n",
    "IP Insights takes in a headerless CSV file with two columns: an entity (username) ID string and the IPv4 address in decimal-dot notation. Fortunately, the Apache Web Server Access Logs output IP addresses and authentcated usernames in their own columns.\n",
    "\n",
    "**Note:** Each website handles user authentication differently. If the Access Log does not output an authenticated user, you could explore the website's query strings or work with your website developers on another solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"user\", \"ip_address\", \"timestamp\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create training and test dataset\n",
    "As part of training a model, we want to evaluate how it generalizes to data it has never seen before.\n",
    "\n",
    "Typically, you create a test set by reserving a random percentage of your dataset and evaluating the model after training. However, for machine learning models that make future predictions on historical data, we want to use out-of-time testing. Instead of randomly sampling our dataset, we split our dataset into two contiguous time windows. The first window is the training set, and the second is the test set. \n",
    "\n",
    "We first look at the time range of our dataset to select a date to use as the partition between the training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6743/52595715.py:1: FutureWarning: Treating datetime data as categorical rather than numeric in `.describe` is deprecated and will be removed in a future version of pandas. Specify `datetime_is_numeric=True` to silence this warning and adopt the future behavior now.\n",
      "  df[\"timestamp\"].describe()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count                 3141309\n",
       "unique                 841160\n",
       "top       2018-11-13 14:20:35\n",
       "freq                       16\n",
       "first     2018-11-04 00:00:02\n",
       "last      2018-11-14 00:00:00\n",
       "Name: timestamp, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"timestamp\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have login events for 10 days. Let's take the first week (7 days) of data as training and then use the last 3 days for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_partition = (\n",
    "    datetime(2018, 11, 11, tzinfo=pytz.FixedOffset(0))\n",
    "    if num_time_zones > 1\n",
    "    else datetime(2018, 11, 11)\n",
    ")\n",
    "\n",
    "train_df = df[df[\"timestamp\"] <= time_partition]\n",
    "test_df = df[df[\"timestamp\"] > time_partition]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our training dataset, we shuffle it. \n",
    "\n",
    "Shuffling improves the model's performance since SageMaker IP Insights uses stochastic gradient descent. This ensures that login events for the same user are less likely to occur in the same mini batch. This allows the model to improve its performance in between predictions of the same user, which will improve training convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644254</th>\n",
       "      <td>user_8378</td>\n",
       "      <td>185.38.66.135</td>\n",
       "      <td>2018-11-10 07:45:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558861</th>\n",
       "      <td>user_1801</td>\n",
       "      <td>206.255.131.165</td>\n",
       "      <td>2018-11-10 20:41:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3115696</th>\n",
       "      <td>user_9812</td>\n",
       "      <td>103.203.228.188</td>\n",
       "      <td>2018-11-09 14:10:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583093</th>\n",
       "      <td>user_1742</td>\n",
       "      <td>63.236.87.196</td>\n",
       "      <td>2018-11-09 01:03:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2592685</th>\n",
       "      <td>user_8041</td>\n",
       "      <td>193.109.199.200</td>\n",
       "      <td>2018-11-06 03:33:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              user       ip_address           timestamp\n",
       "2644254  user_8378    185.38.66.135 2018-11-10 07:45:45\n",
       "558861   user_1801  206.255.131.165 2018-11-10 20:41:21\n",
       "3115696  user_9812  103.203.228.188 2018-11-09 14:10:29\n",
       "583093   user_1742    63.236.87.196 2018-11-09 01:03:47\n",
       "2592685  user_8041  193.109.199.200 2018-11-06 03:33:29"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle train data\n",
    "train_df = train_df.sample(frac=1)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store Data on S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have simulated (or scraped) our datasets, we have to prepare and upload it to S3.\n",
    "\n",
    "We will be doing local inference, therefore we don't need to upload our test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output dataset as headerless CSV\n",
    "train_data = train_df.to_csv(index=False, header=False, columns=[\"user\", \"ip_address\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading data to: s3://sagemaker-us-east-2-160885266928/sagemaker/ipinsights-tutorial/train/train.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03/17/25 18:36:19] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> The class sagemaker.session.s3_input has been renamed in            <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/deprecations.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">deprecations.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/deprecations.py#34\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">34</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         sagemaker&gt;=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>.                                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                  </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         See: <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/v2.html</span> for         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                  </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         details.                                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03/17/25 18:36:19]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m The class sagemaker.session.s3_input has been renamed in            \u001b]8;id=819709;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/deprecations.py\u001b\\\u001b[2mdeprecations.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=805243;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/deprecations.py#34\u001b\\\u001b[2m34\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         sagemaker>=\u001b[1;36m2\u001b[0m.                                                       \u001b[2m                  \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         See: \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/v2.html\u001b[0m for         \u001b[2m                  \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         details.                                                            \u001b[2m                  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Upload data to S3 key\n",
    "train_data_file = \"train.csv\"\n",
    "key = os.path.join(prefix, \"train\", train_data_file)\n",
    "s3_train_data = f\"s3://{bucket}/{key}\"\n",
    "\n",
    "print(f\"Uploading data to: {s3_train_data}\")\n",
    "boto3.resource(\"s3\").Bucket(bucket).Object(key).put(Body=train_data)\n",
    "\n",
    "# Configure SageMaker IP Insights Input Channels\n",
    "input_data = {\n",
    "    \"train\": sagemaker.session.s3_input(\n",
    "        s3_train_data, distribution=\"FullyReplicated\", content_type=\"text/csv\"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "---\n",
    "Once the data is preprocessed and available in the necessary format, the next step is to train our model on the data. There are number of parameters required by the SageMaker IP Insights algorithm to configure the model and define the computational environment in which training will take place. The first of these is to point to a container image which holds the algorithms training and hosting code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03/17/25 18:36:24] </span><span style=\"color: #d7af00; text-decoration-color: #d7af00; font-weight: bold\">WARNING </span> The method get_image_uri has been renamed in sagemaker&gt;=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>.          <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/deprecations.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">deprecations.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/deprecations.py#34\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">34</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         See: <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/v2.html</span> for         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                  </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         details.                                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03/17/25 18:36:24]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;215;175;0mWARNING \u001b[0m The method get_image_uri has been renamed in sagemaker>=\u001b[1;36m2\u001b[0m.          \u001b]8;id=551524;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/deprecations.py\u001b\\\u001b[2mdeprecations.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631215;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/deprecations.py#34\u001b\\\u001b[2m34\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         See: \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/v2.html\u001b[0m for         \u001b[2m                  \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         details.                                                            \u001b[2m                  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Same images used for training and inference. Defaulting to image     <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/image_uris.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">image_uris.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/image_uris.py#393\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">393</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         scope: inference.                                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Same images used for training and inference. Defaulting to image     \u001b]8;id=676733;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/image_uris.py\u001b\\\u001b[2mimage_uris.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=639274;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/image_uris.py#393\u001b\\\u001b[2m393\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         scope: inference.                                                    \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Ignoring unnecessary instance type: <span style=\"color: #e100e1; text-decoration-color: #e100e1; font-style: italic\">None</span>.                            <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/image_uris.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">image_uris.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/image_uris.py#530\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">530</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Ignoring unnecessary instance type: \u001b[3;38;2;225;0;225mNone\u001b[0m.                            \u001b]8;id=609792;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/image_uris.py\u001b\\\u001b[2mimage_uris.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=955193;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/image_uris.py#530\u001b\\\u001b[2m530\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "image = get_image_uri(boto3.Session().region_name, \"ipinsights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we need to determine the training cluster to use. The IP Insights algorithm supports both CPU and GPU training. We recommend using GPU machines as they will train faster. However, when the size of your dataset increases, it can become more economical to use multiple CPU machines running with distributed training. See [Recommended Instance Types](https://docs.aws.amazon.com/sagemaker/latest/dg/ip-insights.html#ip-insights-instances) for more details. \n",
    "\n",
    "### Training Job Configuration\n",
    "- **train_instance_type**: the instance type to train on. We recommend `p3.2xlarge` for single GPU, `p3.8xlarge` for multi-GPU, and `m5.2xlarge` if using distributed training with CPU;\n",
    "- **train_instance_count**: the number of worker nodes in the training cluster.\n",
    "\n",
    "We need to also configure SageMaker IP Insights-specific hypeparameters:\n",
    "\n",
    "### Model Hyperparameters\n",
    "- **num_entity_vectors**: the total number of embeddings to train. We use an internal hashing mechanism to map the entity ID strings to an embedding index; therefore, using an embedding size larger than the total number of possible values helps reduce the number of hash collisions. We recommend this value to be 2x the total number of unique entites (i.e. user names) in your dataset;\n",
    "- **vector_dim**: the size of the entity and IP embedding vectors. The larger the value, the more information can be encoded using these representations but using too large vector representations may cause the model to overfit, especially for small training data sets;\n",
    "- **num_ip_encoder_layers**: the number of layers in the IP encoder network. The larger the number of layers, the higher the model capacity to capture patterns among IP addresses. However, large number of layers increases the chance of overfitting. `num_ip_encoder_layers=1` is a good value to start experimenting with;\n",
    "- **random_negative_sampling_rate**: the number of randomly generated negative samples to produce per 1 positive sample; `random_negative_sampling_rate=1` is a good value to start experimenting with;\n",
    "    - Random negative samples are produced by drawing each octet from a uniform distributed of [0, 255];\n",
    "- **shuffled_negative_sampling_rate**: the number of shuffled negative samples to produce per 1 positive sample; `shuffled_negative_sampling_rate=1` is a good value to start experimenting with;\n",
    "    - Shuffled negative samples are produced by shuffling the accounts within a batch;\n",
    "\n",
    "### Training Hyperparameters\n",
    "- **epochs**: the number of epochs to train. Increase this value if you continue to see the accuracy and cross entropy improving over the last few epochs;\n",
    "- **mini_batch_size**: how many examples in each mini_batch. A smaller number improves convergence with stochastic gradient descent. But a larger number is necessary if using shuffled_negative_sampling to avoid sampling a wrong account for a negative sample;\n",
    "- **learning_rate**: the learning rate for the Adam optimizer (try ranges in [0.001, 0.1]). Too large learning rate may cause the model to diverge since the training would be likely to overshoot minima. On the other hand, too small learning rate slows down the convergence;\n",
    "- **weight_decay**: L2 regularization coefficient. Regularization is required to prevent the model from overfitting the training data. Too large of a value will prevent the model from learning anything;\n",
    "\n",
    "For more details, see [Amazon SageMaker IP Insights (Hyperparameters)](https://docs.aws.amazon.com/sagemaker/latest/dg/ip-insights-hyperparameters.html). Additionally, most of these hyperparameters can be found using SageMaker Automatic Model Tuning; see [Amazon SageMaker IP Insights (Model Tuning)](https://docs.aws.amazon.com/sagemaker/latest/dg/ip-insights-tuning.html) for more details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03/17/25 18:37:14] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> SageMaker Python SDK will collect telemetry to help us better  <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/telemetry/telemetry_logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">telemetry_logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/telemetry/telemetry_logging.py#91\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">91</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         understand our user's needs, diagnose issues, and deliver      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         additional features.                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To opt out of telemetry, please disable via TelemetryOptOut    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         parameter in SDK defaults config. For more information, refer  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/overview.html#confi</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">guring-and-using-defaults-with-the-sagemaker-python-sdk.</span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03/17/25 18:37:14]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m SageMaker Python SDK will collect telemetry to help us better  \u001b]8;id=13251;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/telemetry/telemetry_logging.py\u001b\\\u001b[2mtelemetry_logging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=742586;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/telemetry/telemetry_logging.py#91\u001b\\\u001b[2m91\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         understand our user's needs, diagnose issues, and deliver      \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         additional features.                                           \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To opt out of telemetry, please disable via TelemetryOptOut    \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         parameter in SDK defaults config. For more information, refer  \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to                                                             \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/overview.html#confi\u001b[0m \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mguring-and-using-defaults-with-the-sagemaker-python-sdk.\u001b[0m       \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating training-job with name: ipinsights-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-03-17-18-37-14-430    <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#1042\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1042</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating training-job with name: ipinsights-\u001b[1;36m2025\u001b[0m-03-17-18-37-14-430    \u001b]8;id=227917;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=228114;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#1042\u001b\\\u001b[2m1042\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-17 18:37:16 Starting - Starting the training job...\n",
      "..25-03-17 18:37:49 Downloading - Downloading input data.\n",
      "..............38:05 Downloading - Downloading the training image.\n",
      "\u001b[34mDocker entrypoint called with argument(s): train\u001b[0mmpleted. Training in progress..\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.8/site-packages/mxnet/model.py:97: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if num_device is 1 and 'dist' not in kvstore:\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.8/site-packages/scipy/optimize/_shgo.py:495: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if cons['type'] is 'ineq':\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.8/site-packages/scipy/optimize/_shgo.py:743: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if len(self.X_min) is not 0:\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:40:48 INFO 139841683838784] Reading default configuration from /opt/amazon/lib/python3.8/site-packages/algorithm/resources/default-input.json: {'batch_metrics_publish_interval': '1000', 'epochs': '10', 'learning_rate': '0.001', 'mini_batch_size': '5000', 'num_entity_vectors': '100000', 'num_ip_encoder_layers': '1', 'random_negative_sampling_rate': '1', 'shuffled_negative_sampling_rate': '1', 'vector_dim': '128', 'weight_decay': '0.00001', '_kvstore': 'auto_gpu', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': ''}\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:40:48 INFO 139841683838784] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'epochs': '5', 'learning_rate': '0.01', 'mini_batch_size': '1000', 'num_entity_vectors': '20000', 'random_negative_sampling_rate': '5', 'vector_dim': '128'}\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:40:48 INFO 139841683838784] Final configuration: {'batch_metrics_publish_interval': '1000', 'epochs': '5', 'learning_rate': '0.01', 'mini_batch_size': '1000', 'num_entity_vectors': '20000', 'num_ip_encoder_layers': '1', 'random_negative_sampling_rate': '5', 'shuffled_negative_sampling_rate': '1', 'vector_dim': '128', 'weight_decay': '0.00001', '_kvstore': 'auto_gpu', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': ''}\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:40:48 WARNING 139841683838784] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m/opt/amazon/python3.8/lib/python3.8/subprocess.py:848: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:40:48 INFO 139841683838784] nvidia-smi: took 0.032 seconds to run.\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:40:48 INFO 139841683838784] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34mProcess 7 is a worker.\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:40:48 INFO 139841683838784] Using default worker.\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:40:48 INFO 139841683838784] Loaded iterator creator application/x-ndarray for content type ('application/x-ndarray', '1.0')\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:40:48 INFO 139841683838784] Loaded iterator creator text/csv for content type ('text/csv', '1.0')\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:40:49 INFO 139841683838784] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:40:49 INFO 139841683838784] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1742236849.080983, \"EndTime\": 1742236849.083556, \"Dimensions\": {\"Algorithm\": \"ipinsights\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 2.3975372314453125, \"count\": 1, \"min\": 2.3975372314453125, \"max\": 2.3975372314453125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1742236849.0836408, \"EndTime\": 1742236849.0836704, \"Dimensions\": {\"Algorithm\": \"ipinsights\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:40:49 INFO 139841683838784] Create Store: local\u001b[0m\n",
      "\u001b[34m[18:40:49] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_11.1.x.406.0/AL2_x86_64/generic-flavor/src/src/kvstore/./kvstore_local.h:306: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use kv.row_sparse_pull() or module.prepare() with row_ids.\u001b[0m\n",
      "\u001b[34m[18:40:49] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_11.1.x.406.0/AL2_x86_64/generic-flavor/src/src/operator/././../common/utils.h:450: Optimizer with lazy_update = True detected. Be aware that lazy update with row_sparse gradient is different from standard update, and may lead to different empirical results. See https://mxnet.incubator.apache.org/api/python/optimization/optimization.html for more details.\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:40:49 INFO 139841683838784] #quality_metric: host=algo-1, epoch=0, batch=0 train binary_classification_accuracy <score>=0.52\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:40:49 INFO 139841683838784] #quality_metric: host=algo-1, epoch=0, batch=0 train binary_classification_cross_entropy <loss>=0.6930449829101563\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:40:57 INFO 139841683838784] Epoch[0] Batch [1000]#011Speed: 113411.83 samples/sec#011binary_classification_accuracy=0.928039#011binary_classification_cross_entropy=0.197253\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:40:57 INFO 139841683838784] #quality_metric: host=algo-1, epoch=0, batch=1000 train binary_classification_accuracy <score>=0.928038961038961\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:40:57 INFO 139841683838784] #quality_metric: host=algo-1, epoch=0, batch=1000 train binary_classification_cross_entropy <loss>=0.19725321550397845\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:41:06 INFO 139841683838784] Epoch[0] Batch [2000]#011Speed: 115244.60 samples/sec#011binary_classification_accuracy=0.950202#011binary_classification_cross_entropy=0.147261\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:41:06 INFO 139841683838784] #quality_metric: host=algo-1, epoch=0, batch=2000 train binary_classification_accuracy <score>=0.9502023988005996\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:41:06 INFO 139841683838784] #quality_metric: host=algo-1, epoch=0, batch=2000 train binary_classification_cross_entropy <loss>=0.14726076437984925\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:41:15 INFO 139841683838784] Epoch[0] Batch [3000]#011Speed: 114824.68 samples/sec#011binary_classification_accuracy=0.959725#011binary_classification_cross_entropy=0.124965\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:41:15 INFO 139841683838784] #quality_metric: host=algo-1, epoch=0, batch=3000 train binary_classification_accuracy <score>=0.9597250916361213\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:41:15 INFO 139841683838784] #quality_metric: host=algo-1, epoch=0, batch=3000 train binary_classification_cross_entropy <loss>=0.12496473982269786\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:41:24 INFO 139841683838784] Epoch[0] Batch [4000]#011Speed: 114930.67 samples/sec#011binary_classification_accuracy=0.965056#011binary_classification_cross_entropy=0.112350\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:41:24 INFO 139841683838784] #quality_metric: host=algo-1, epoch=0, batch=4000 train binary_classification_accuracy <score>=0.9650564858785303\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:41:24 INFO 139841683838784] #quality_metric: host=algo-1, epoch=0, batch=4000 train binary_classification_cross_entropy <loss>=0.1123498715012409\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:41:32 INFO 139841683838784] Epoch[0] Batch [5000]#011Speed: 115644.77 samples/sec#011binary_classification_accuracy=0.968579#011binary_classification_cross_entropy=0.103911\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:41:32 INFO 139841683838784] #quality_metric: host=algo-1, epoch=0, batch=5000 train binary_classification_accuracy <score>=0.9685788842231554\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:41:32 INFO 139841683838784] #quality_metric: host=algo-1, epoch=0, batch=5000 train binary_classification_cross_entropy <loss>=0.10391144024079095\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:41:41 INFO 139841683838784] Epoch[0] Batch [6000]#011Speed: 115274.62 samples/sec#011binary_classification_accuracy=0.971005#011binary_classification_cross_entropy=0.098110\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:41:41 INFO 139841683838784] #quality_metric: host=algo-1, epoch=0, batch=6000 train binary_classification_accuracy <score>=0.9710053324445925\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:41:41 INFO 139841683838784] #quality_metric: host=algo-1, epoch=0, batch=6000 train binary_classification_cross_entropy <loss>=0.09810961071059537\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:41:50 INFO 139841683838784] Epoch[0] Batch [7000]#011Speed: 115137.09 samples/sec#011binary_classification_accuracy=0.972868#011binary_classification_cross_entropy=0.093610\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:41:50 INFO 139841683838784] #quality_metric: host=algo-1, epoch=0, batch=7000 train binary_classification_accuracy <score>=0.9728675903442365\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:41:50 INFO 139841683838784] #quality_metric: host=algo-1, epoch=0, batch=7000 train binary_classification_cross_entropy <loss>=0.0936098778207989\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:41:58 INFO 139841683838784] Epoch[0] Batch [8000]#011Speed: 115098.83 samples/sec#011binary_classification_accuracy=0.974320#011binary_classification_cross_entropy=0.089996\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:41:58 INFO 139841683838784] #quality_metric: host=algo-1, epoch=0, batch=8000 train binary_classification_accuracy <score>=0.9743199600049994\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:41:58 INFO 139841683838784] #quality_metric: host=algo-1, epoch=0, batch=8000 train binary_classification_cross_entropy <loss>=0.08999635065872809\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:42:07 INFO 139841683838784] Epoch[0] Batch [9000]#011Speed: 114784.47 samples/sec#011binary_classification_accuracy=0.975455#011binary_classification_cross_entropy=0.087217\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:42:07 INFO 139841683838784] #quality_metric: host=algo-1, epoch=0, batch=9000 train binary_classification_accuracy <score>=0.9754548383512943\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:42:07 INFO 139841683838784] #quality_metric: host=algo-1, epoch=0, batch=9000 train binary_classification_cross_entropy <loss>=0.08721672693542236\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:42:16 INFO 139841683838784] Epoch[0] Batch [10000]#011Speed: 114965.07 samples/sec#011binary_classification_accuracy=0.976427#011binary_classification_cross_entropy=0.084864\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:42:16 INFO 139841683838784] #quality_metric: host=algo-1, epoch=0, batch=10000 train binary_classification_accuracy <score>=0.9764266573342666\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:42:16 INFO 139841683838784] #quality_metric: host=algo-1, epoch=0, batch=10000 train binary_classification_cross_entropy <loss>=0.08486373054150426\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:42:24 INFO 139841683838784] Epoch[0] Batch [11000]#011Speed: 115078.32 samples/sec#011binary_classification_accuracy=0.977220#011binary_classification_cross_entropy=0.082943\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:42:24 INFO 139841683838784] #quality_metric: host=algo-1, epoch=0, batch=11000 train binary_classification_accuracy <score>=0.9772202527042996\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:42:24 INFO 139841683838784] #quality_metric: host=algo-1, epoch=0, batch=11000 train binary_classification_cross_entropy <loss>=0.08294259765197792\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:42:33 INFO 139841683838784] Epoch[0] Batch [12000]#011Speed: 116280.91 samples/sec#011binary_classification_accuracy=0.977898#011binary_classification_cross_entropy=0.081266\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:42:33 INFO 139841683838784] #quality_metric: host=algo-1, epoch=0, batch=12000 train binary_classification_accuracy <score>=0.9778975918673444\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:42:33 INFO 139841683838784] #quality_metric: host=algo-1, epoch=0, batch=12000 train binary_classification_cross_entropy <loss>=0.08126582272789218\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:42:42 INFO 139841683838784] Epoch[0] Batch [13000]#011Speed: 114938.95 samples/sec#011binary_classification_accuracy=0.978494#011binary_classification_cross_entropy=0.079822\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:42:42 INFO 139841683838784] #quality_metric: host=algo-1, epoch=0, batch=13000 train binary_classification_accuracy <score>=0.9784937312514422\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:42:42 INFO 139841683838784] #quality_metric: host=algo-1, epoch=0, batch=13000 train binary_classification_cross_entropy <loss>=0.07982243789580132\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:42:50 INFO 139841683838784] Epoch[0] Batch [14000]#011Speed: 115745.86 samples/sec#011binary_classification_accuracy=0.979018#011binary_classification_cross_entropy=0.078550\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:42:50 INFO 139841683838784] #quality_metric: host=algo-1, epoch=0, batch=14000 train binary_classification_accuracy <score>=0.979018427255196\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:42:50 INFO 139841683838784] #quality_metric: host=algo-1, epoch=0, batch=14000 train binary_classification_cross_entropy <loss>=0.07855019276490016\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:42:59 INFO 139841683838784] Epoch[0] Batch [15000]#011Speed: 115926.88 samples/sec#011binary_classification_accuracy=0.979479#011binary_classification_cross_entropy=0.077438\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:42:59 INFO 139841683838784] #quality_metric: host=algo-1, epoch=0, batch=15000 train binary_classification_accuracy <score>=0.9794789014065729\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:42:59 INFO 139841683838784] #quality_metric: host=algo-1, epoch=0, batch=15000 train binary_classification_cross_entropy <loss>=0.07743770764238174\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:43:02 INFO 139841683838784] Epoch[0] Train-binary_classification_accuracy=0.979639\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:43:02 INFO 139841683838784] Epoch[0] Train-binary_classification_cross_entropy=0.077032\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:43:02 INFO 139841683838784] Epoch[0] Time cost=133.797\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:43:02 INFO 139841683838784] #quality_metric: host=algo-1, epoch=0, train binary_classification_accuracy <score>=0.979639090909091\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:43:02 INFO 139841683838784] #quality_metric: host=algo-1, epoch=0, train binary_classification_cross_entropy <loss>=0.07703227047783988\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1742236849.0836139, \"EndTime\": 1742236982.8898914, \"Dimensions\": {\"Algorithm\": \"ipinsights\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"update.time\": {\"sum\": 133806.05959892273, \"count\": 1, \"min\": 133806.05959892273, \"max\": 133806.05959892273}}}\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:43:02 INFO 139841683838784] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1742236849.0838003, \"EndTime\": 1742236982.8901725, \"Dimensions\": {\"Algorithm\": \"ipinsights\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 15395639.0, \"count\": 1, \"min\": 15395639, \"max\": 15395639}, \"Total Batches Seen\": {\"sum\": 15400.0, \"count\": 1, \"min\": 15400, \"max\": 15400}, \"Max Records Seen Between Resets\": {\"sum\": 15395639.0, \"count\": 1, \"min\": 15395639, \"max\": 15395639}, \"Max Batches Seen Between Resets\": {\"sum\": 15400.0, \"count\": 1, \"min\": 15400, \"max\": 15400}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:43:02 INFO 139841683838784] #throughput_metric: host=algo-1, train throughput=115058.98580721163 records/second\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:43:02 WARNING 139841683838784] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.8/site-packages/mxnet/module/base_module.py:501: UserWarning: Parameters already initialized and force_init=False. init_params call ignored.\n",
      "  self.init_params(initializer=initializer, arg_params=arg_params, aux_params=aux_params,\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:43:02 WARNING 139841683838784] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:43:02 INFO 139841683838784] #quality_metric: host=algo-1, epoch=1, batch=0 train binary_classification_accuracy <score>=0.987\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:43:02 INFO 139841683838784] #quality_metric: host=algo-1, epoch=1, batch=0 train binary_classification_cross_entropy <loss>=0.05078853607177734\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:43:11 INFO 139841683838784] Epoch[1] Batch [1000]#011Speed: 112865.80 samples/sec#011binary_classification_accuracy=0.986050#011binary_classification_cross_entropy=0.059537\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:43:11 INFO 139841683838784] #quality_metric: host=algo-1, epoch=1, batch=1000 train binary_classification_accuracy <score>=0.98604995004995\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:43:11 INFO 139841683838784] #quality_metric: host=algo-1, epoch=1, batch=1000 train binary_classification_cross_entropy <loss>=0.05953712091055307\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:43:20 INFO 139841683838784] Epoch[1] Batch [2000]#011Speed: 113658.90 samples/sec#011binary_classification_accuracy=0.986050#011binary_classification_cross_entropy=0.059431\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:43:20 INFO 139841683838784] #quality_metric: host=algo-1, epoch=1, batch=2000 train binary_classification_accuracy <score>=0.9860504747626186\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:43:20 INFO 139841683838784] #quality_metric: host=algo-1, epoch=1, batch=2000 train binary_classification_cross_entropy <loss>=0.05943128845847767\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:43:29 INFO 139841683838784] Epoch[1] Batch [3000]#011Speed: 113378.26 samples/sec#011binary_classification_accuracy=0.986063#011binary_classification_cross_entropy=0.059167\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:43:29 INFO 139841683838784] #quality_metric: host=algo-1, epoch=1, batch=3000 train binary_classification_accuracy <score>=0.9860629790069977\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:43:29 INFO 139841683838784] #quality_metric: host=algo-1, epoch=1, batch=3000 train binary_classification_cross_entropy <loss>=0.05916685616703917\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:43:38 INFO 139841683838784] Epoch[1] Batch [4000]#011Speed: 112953.18 samples/sec#011binary_classification_accuracy=0.986068#011binary_classification_cross_entropy=0.059174\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:43:38 INFO 139841683838784] #quality_metric: host=algo-1, epoch=1, batch=4000 train binary_classification_accuracy <score>=0.9860677330667333\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:43:38 INFO 139841683838784] #quality_metric: host=algo-1, epoch=1, batch=4000 train binary_classification_cross_entropy <loss>=0.05917352034586187\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:43:47 INFO 139841683838784] Epoch[1] Batch [5000]#011Speed: 113528.04 samples/sec#011binary_classification_accuracy=0.986104#011binary_classification_cross_entropy=0.059042\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:43:47 INFO 139841683838784] #quality_metric: host=algo-1, epoch=1, batch=5000 train binary_classification_accuracy <score>=0.9861035792841432\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:43:47 INFO 139841683838784] #quality_metric: host=algo-1, epoch=1, batch=5000 train binary_classification_cross_entropy <loss>=0.059042000737578315\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:43:55 INFO 139841683838784] Epoch[1] Batch [6000]#011Speed: 113050.65 samples/sec#011binary_classification_accuracy=0.986129#011binary_classification_cross_entropy=0.059058\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:43:55 INFO 139841683838784] #quality_metric: host=algo-1, epoch=1, batch=6000 train binary_classification_accuracy <score>=0.9861288118646893\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:43:55 INFO 139841683838784] #quality_metric: host=algo-1, epoch=1, batch=6000 train binary_classification_cross_entropy <loss>=0.05905805716111727\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:44:04 INFO 139841683838784] Epoch[1] Batch [7000]#011Speed: 112414.50 samples/sec#011binary_classification_accuracy=0.986125#011binary_classification_cross_entropy=0.059018\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:44:04 INFO 139841683838784] #quality_metric: host=algo-1, epoch=1, batch=7000 train binary_classification_accuracy <score>=0.9861248393086702\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:44:04 INFO 139841683838784] #quality_metric: host=algo-1, epoch=1, batch=7000 train binary_classification_cross_entropy <loss>=0.05901761209465847\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:44:13 INFO 139841683838784] Epoch[1] Batch [8000]#011Speed: 112537.67 samples/sec#011binary_classification_accuracy=0.986163#011binary_classification_cross_entropy=0.058867\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:44:13 INFO 139841683838784] #quality_metric: host=algo-1, epoch=1, batch=8000 train binary_classification_accuracy <score>=0.9861633545806774\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:44:13 INFO 139841683838784] #quality_metric: host=algo-1, epoch=1, batch=8000 train binary_classification_cross_entropy <loss>=0.058866617971562604\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:44:22 INFO 139841683838784] Epoch[1] Batch [9000]#011Speed: 113314.84 samples/sec#011binary_classification_accuracy=0.986175#011binary_classification_cross_entropy=0.058849\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:44:22 INFO 139841683838784] #quality_metric: host=algo-1, epoch=1, batch=9000 train binary_classification_accuracy <score>=0.9861745361626486\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:44:22 INFO 139841683838784] #quality_metric: host=algo-1, epoch=1, batch=9000 train binary_classification_cross_entropy <loss>=0.058849032407230224\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:44:31 INFO 139841683838784] Epoch[1] Batch [10000]#011Speed: 112748.55 samples/sec#011binary_classification_accuracy=0.986200#011binary_classification_cross_entropy=0.058770\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:44:31 INFO 139841683838784] #quality_metric: host=algo-1, epoch=1, batch=10000 train binary_classification_accuracy <score>=0.9862003799620038\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:44:31 INFO 139841683838784] #quality_metric: host=algo-1, epoch=1, batch=10000 train binary_classification_cross_entropy <loss>=0.05876997746583069\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:44:40 INFO 139841683838784] Epoch[1] Batch [11000]#011Speed: 113328.33 samples/sec#011binary_classification_accuracy=0.986212#011binary_classification_cross_entropy=0.058721\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:44:40 INFO 139841683838784] #quality_metric: host=algo-1, epoch=1, batch=11000 train binary_classification_accuracy <score>=0.9862115262248886\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:44:40 INFO 139841683838784] #quality_metric: host=algo-1, epoch=1, batch=11000 train binary_classification_cross_entropy <loss>=0.05872108348267001\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:44:48 INFO 139841683838784] Epoch[1] Batch [12000]#011Speed: 114345.54 samples/sec#011binary_classification_accuracy=0.986226#011binary_classification_cross_entropy=0.058677\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:44:48 INFO 139841683838784] #quality_metric: host=algo-1, epoch=1, batch=12000 train binary_classification_accuracy <score>=0.9862256478626781\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:44:48 INFO 139841683838784] #quality_metric: host=algo-1, epoch=1, batch=12000 train binary_classification_cross_entropy <loss>=0.05867716628517194\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:44:57 INFO 139841683838784] Epoch[1] Batch [13000]#011Speed: 112821.94 samples/sec#011binary_classification_accuracy=0.986239#011binary_classification_cross_entropy=0.058633\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:44:57 INFO 139841683838784] #quality_metric: host=algo-1, epoch=1, batch=13000 train binary_classification_accuracy <score>=0.9862386739481578\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:44:57 INFO 139841683838784] #quality_metric: host=algo-1, epoch=1, batch=13000 train binary_classification_cross_entropy <loss>=0.05863296508759721\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:45:06 INFO 139841683838784] Epoch[1] Batch [14000]#011Speed: 112978.03 samples/sec#011binary_classification_accuracy=0.986271#011binary_classification_cross_entropy=0.058563\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:45:06 INFO 139841683838784] #quality_metric: host=algo-1, epoch=1, batch=14000 train binary_classification_accuracy <score>=0.986270623526891\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:45:06 INFO 139841683838784] #quality_metric: host=algo-1, epoch=1, batch=14000 train binary_classification_cross_entropy <loss>=0.0585628928021102\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:45:15 INFO 139841683838784] Epoch[1] Batch [15000]#011Speed: 113406.31 samples/sec#011binary_classification_accuracy=0.986292#011binary_classification_cross_entropy=0.058557\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:45:15 INFO 139841683838784] #quality_metric: host=algo-1, epoch=1, batch=15000 train binary_classification_accuracy <score>=0.986291713885741\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:45:15 INFO 139841683838784] #quality_metric: host=algo-1, epoch=1, batch=15000 train binary_classification_cross_entropy <loss>=0.058556899360828134\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:45:18 INFO 139841683838784] Epoch[1] Train-binary_classification_accuracy=0.986297\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:45:18 INFO 139841683838784] Epoch[1] Train-binary_classification_cross_entropy=0.058532\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:45:18 INFO 139841683838784] Epoch[1] Time cost=136.094\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:45:18 INFO 139841683838784] #quality_metric: host=algo-1, epoch=1, train binary_classification_accuracy <score>=0.9862971428571429\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:45:18 INFO 139841683838784] #quality_metric: host=algo-1, epoch=1, train binary_classification_cross_entropy <loss>=0.058531504840974684\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1742236982.889981, \"EndTime\": 1742237118.9887035, \"Dimensions\": {\"Algorithm\": \"ipinsights\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 136098.25134277344, \"count\": 1, \"min\": 136098.25134277344, \"max\": 136098.25134277344}}}\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:45:18 INFO 139841683838784] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1742236982.8904266, \"EndTime\": 1742237118.98892, \"Dimensions\": {\"Algorithm\": \"ipinsights\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 30791278.0, \"count\": 1, \"min\": 30791278, \"max\": 30791278}, \"Total Batches Seen\": {\"sum\": 30800.0, \"count\": 1, \"min\": 30800, \"max\": 30800}, \"Max Records Seen Between Resets\": {\"sum\": 15395639.0, \"count\": 1, \"min\": 15395639, \"max\": 15395639}, \"Max Batches Seen Between Resets\": {\"sum\": 15400.0, \"count\": 1, \"min\": 15400, \"max\": 15400}, \"Reset Count\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:45:18 INFO 139841683838784] #throughput_metric: host=algo-1, train throughput=113121.1959122926 records/second\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:45:18 WARNING 139841683838784] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:45:18 WARNING 139841683838784] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:45:19 INFO 139841683838784] #quality_metric: host=algo-1, epoch=2, batch=0 train binary_classification_accuracy <score>=0.984\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:45:19 INFO 139841683838784] #quality_metric: host=algo-1, epoch=2, batch=0 train binary_classification_cross_entropy <loss>=0.06399895477294922\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:45:27 INFO 139841683838784] Epoch[2] Batch [1000]#011Speed: 114742.58 samples/sec#011binary_classification_accuracy=0.986652#011binary_classification_cross_entropy=0.056527\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:45:27 INFO 139841683838784] #quality_metric: host=algo-1, epoch=2, batch=1000 train binary_classification_accuracy <score>=0.9866523476523477\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:45:27 INFO 139841683838784] #quality_metric: host=algo-1, epoch=2, batch=1000 train binary_classification_cross_entropy <loss>=0.056527056260542434\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:45:36 INFO 139841683838784] Epoch[2] Batch [2000]#011Speed: 115369.94 samples/sec#011binary_classification_accuracy=0.986664#011binary_classification_cross_entropy=0.056661\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:45:36 INFO 139841683838784] #quality_metric: host=algo-1, epoch=2, batch=2000 train binary_classification_accuracy <score>=0.986663668165917\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:45:36 INFO 139841683838784] #quality_metric: host=algo-1, epoch=2, batch=2000 train binary_classification_cross_entropy <loss>=0.05666068977954565\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:45:45 INFO 139841683838784] Epoch[2] Batch [3000]#011Speed: 115384.99 samples/sec#011binary_classification_accuracy=0.986688#011binary_classification_cross_entropy=0.056484\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:45:45 INFO 139841683838784] #quality_metric: host=algo-1, epoch=2, batch=3000 train binary_classification_accuracy <score>=0.9866884371876041\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:45:45 INFO 139841683838784] #quality_metric: host=algo-1, epoch=2, batch=3000 train binary_classification_cross_entropy <loss>=0.0564837095952757\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:45:53 INFO 139841683838784] Epoch[2] Batch [4000]#011Speed: 115776.63 samples/sec#011binary_classification_accuracy=0.986718#011binary_classification_cross_entropy=0.056490\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:45:53 INFO 139841683838784] #quality_metric: host=algo-1, epoch=2, batch=4000 train binary_classification_accuracy <score>=0.9867178205448638\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:45:53 INFO 139841683838784] #quality_metric: host=algo-1, epoch=2, batch=4000 train binary_classification_cross_entropy <loss>=0.05648981531272379\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:46:02 INFO 139841683838784] Epoch[2] Batch [5000]#011Speed: 114642.27 samples/sec#011binary_classification_accuracy=0.986712#011binary_classification_cross_entropy=0.056534\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:46:02 INFO 139841683838784] #quality_metric: host=algo-1, epoch=2, batch=5000 train binary_classification_accuracy <score>=0.9867120575884823\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:46:02 INFO 139841683838784] #quality_metric: host=algo-1, epoch=2, batch=5000 train binary_classification_cross_entropy <loss>=0.05653417582017044\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:46:11 INFO 139841683838784] Epoch[2] Batch [6000]#011Speed: 114558.48 samples/sec#011binary_classification_accuracy=0.986684#011binary_classification_cross_entropy=0.056608\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:46:11 INFO 139841683838784] #quality_metric: host=algo-1, epoch=2, batch=6000 train binary_classification_accuracy <score>=0.9866840526578904\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:46:11 INFO 139841683838784] #quality_metric: host=algo-1, epoch=2, batch=6000 train binary_classification_cross_entropy <loss>=0.05660787187451383\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:46:19 INFO 139841683838784] Epoch[2] Batch [7000]#011Speed: 114606.35 samples/sec#011binary_classification_accuracy=0.986654#011binary_classification_cross_entropy=0.056651\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:46:19 INFO 139841683838784] #quality_metric: host=algo-1, epoch=2, batch=7000 train binary_classification_accuracy <score>=0.9866539065847736\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:46:19 INFO 139841683838784] #quality_metric: host=algo-1, epoch=2, batch=7000 train binary_classification_cross_entropy <loss>=0.05665147695635373\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:46:28 INFO 139841683838784] Epoch[2] Batch [8000]#011Speed: 115229.88 samples/sec#011binary_classification_accuracy=0.986686#011binary_classification_cross_entropy=0.056508\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:46:28 INFO 139841683838784] #quality_metric: host=algo-1, epoch=2, batch=8000 train binary_classification_accuracy <score>=0.9866862892138483\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:46:28 INFO 139841683838784] #quality_metric: host=algo-1, epoch=2, batch=8000 train binary_classification_cross_entropy <loss>=0.05650826618936923\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:46:37 INFO 139841683838784] Epoch[2] Batch [9000]#011Speed: 116028.33 samples/sec#011binary_classification_accuracy=0.986669#011binary_classification_cross_entropy=0.056560\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:46:37 INFO 139841683838784] #quality_metric: host=algo-1, epoch=2, batch=9000 train binary_classification_accuracy <score>=0.986668925674925\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:46:37 INFO 139841683838784] #quality_metric: host=algo-1, epoch=2, batch=9000 train binary_classification_cross_entropy <loss>=0.05656024361928163\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:46:45 INFO 139841683838784] Epoch[2] Batch [10000]#011Speed: 115818.58 samples/sec#011binary_classification_accuracy=0.986687#011binary_classification_cross_entropy=0.056504\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:46:45 INFO 139841683838784] #quality_metric: host=algo-1, epoch=2, batch=10000 train binary_classification_accuracy <score>=0.9866873312668734\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:46:45 INFO 139841683838784] #quality_metric: host=algo-1, epoch=2, batch=10000 train binary_classification_cross_entropy <loss>=0.05650385502335692\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:46:54 INFO 139841683838784] Epoch[2] Batch [11000]#011Speed: 115821.33 samples/sec#011binary_classification_accuracy=0.986689#011binary_classification_cross_entropy=0.056520\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:46:54 INFO 139841683838784] #quality_metric: host=algo-1, epoch=2, batch=11000 train binary_classification_accuracy <score>=0.9866886646668485\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:46:54 INFO 139841683838784] #quality_metric: host=algo-1, epoch=2, batch=11000 train binary_classification_cross_entropy <loss>=0.05652005127323464\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:47:03 INFO 139841683838784] Epoch[2] Batch [12000]#011Speed: 114450.40 samples/sec#011binary_classification_accuracy=0.986704#011binary_classification_cross_entropy=0.056497\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:47:03 INFO 139841683838784] #quality_metric: host=algo-1, epoch=2, batch=12000 train binary_classification_accuracy <score>=0.9867040246646113\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:47:03 INFO 139841683838784] #quality_metric: host=algo-1, epoch=2, batch=12000 train binary_classification_cross_entropy <loss>=0.05649716856503286\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:47:11 INFO 139841683838784] Epoch[2] Batch [13000]#011Speed: 115057.47 samples/sec#011binary_classification_accuracy=0.986699#011binary_classification_cross_entropy=0.056513\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:47:11 INFO 139841683838784] #quality_metric: host=algo-1, epoch=2, batch=13000 train binary_classification_accuracy <score>=0.986699330820706\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:47:11 INFO 139841683838784] #quality_metric: host=algo-1, epoch=2, batch=13000 train binary_classification_cross_entropy <loss>=0.0565125832604258\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:47:20 INFO 139841683838784] Epoch[2] Batch [14000]#011Speed: 114979.13 samples/sec#011binary_classification_accuracy=0.986717#011binary_classification_cross_entropy=0.056464\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:47:20 INFO 139841683838784] #quality_metric: host=algo-1, epoch=2, batch=14000 train binary_classification_accuracy <score>=0.9867165916720234\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:47:20 INFO 139841683838784] #quality_metric: host=algo-1, epoch=2, batch=14000 train binary_classification_cross_entropy <loss>=0.05646371150256889\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:47:29 INFO 139841683838784] Epoch[2] Batch [15000]#011Speed: 115220.53 samples/sec#011binary_classification_accuracy=0.986719#011binary_classification_cross_entropy=0.056459\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:47:29 INFO 139841683838784] #quality_metric: host=algo-1, epoch=2, batch=15000 train binary_classification_accuracy <score>=0.9867185520965269\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:47:29 INFO 139841683838784] #quality_metric: host=algo-1, epoch=2, batch=15000 train binary_classification_cross_entropy <loss>=0.05645866610627041\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:47:32 INFO 139841683838784] Epoch[2] Train-binary_classification_accuracy=0.986724\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:47:32 INFO 139841683838784] Epoch[2] Train-binary_classification_cross_entropy=0.056425\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:47:32 INFO 139841683838784] Epoch[2] Time cost=133.706\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:47:32 INFO 139841683838784] #quality_metric: host=algo-1, epoch=2, train binary_classification_accuracy <score>=0.9867242857142857\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:47:32 INFO 139841683838784] #quality_metric: host=algo-1, epoch=2, train binary_classification_cross_entropy <loss>=0.05642488014958121\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1742237118.9887621, \"EndTime\": 1742237252.6993582, \"Dimensions\": {\"Algorithm\": \"ipinsights\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 133710.16812324524, \"count\": 1, \"min\": 133710.16812324524, \"max\": 133710.16812324524}}}\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:47:32 INFO 139841683838784] #progress_metric: host=algo-1, completed 60.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1742237118.9891605, \"EndTime\": 1742237252.6996086, \"Dimensions\": {\"Algorithm\": \"ipinsights\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 46186917.0, \"count\": 1, \"min\": 46186917, \"max\": 46186917}, \"Total Batches Seen\": {\"sum\": 46200.0, \"count\": 1, \"min\": 46200, \"max\": 46200}, \"Max Records Seen Between Resets\": {\"sum\": 15395639.0, \"count\": 1, \"min\": 15395639, \"max\": 15395639}, \"Max Batches Seen Between Resets\": {\"sum\": 15400.0, \"count\": 1, \"min\": 15400, \"max\": 15400}, \"Reset Count\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:47:32 INFO 139841683838784] #throughput_metric: host=algo-1, train throughput=115141.53174160475 records/second\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:47:32 WARNING 139841683838784] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:47:32 WARNING 139841683838784] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:47:32 INFO 139841683838784] #quality_metric: host=algo-1, epoch=3, batch=0 train binary_classification_accuracy <score>=0.98\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:47:32 INFO 139841683838784] #quality_metric: host=algo-1, epoch=3, batch=0 train binary_classification_cross_entropy <loss>=0.07379945373535156\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:47:41 INFO 139841683838784] Epoch[3] Batch [1000]#011Speed: 112424.22 samples/sec#011binary_classification_accuracy=0.986963#011binary_classification_cross_entropy=0.055148\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:47:41 INFO 139841683838784] #quality_metric: host=algo-1, epoch=3, batch=1000 train binary_classification_accuracy <score>=0.986963036963037\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:47:41 INFO 139841683838784] #quality_metric: host=algo-1, epoch=3, batch=1000 train binary_classification_cross_entropy <loss>=0.05514805038063438\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:47:50 INFO 139841683838784] Epoch[3] Batch [2000]#011Speed: 113434.87 samples/sec#011binary_classification_accuracy=0.986888#011binary_classification_cross_entropy=0.055578\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:47:50 INFO 139841683838784] #quality_metric: host=algo-1, epoch=3, batch=2000 train binary_classification_accuracy <score>=0.9868875562218891\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:47:50 INFO 139841683838784] #quality_metric: host=algo-1, epoch=3, batch=2000 train binary_classification_cross_entropy <loss>=0.0555784395085401\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:47:59 INFO 139841683838784] Epoch[3] Batch [3000]#011Speed: 113159.58 samples/sec#011binary_classification_accuracy=0.986904#011binary_classification_cross_entropy=0.055425\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:47:59 INFO 139841683838784] #quality_metric: host=algo-1, epoch=3, batch=3000 train binary_classification_accuracy <score>=0.9869036987670776\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:47:59 INFO 139841683838784] #quality_metric: host=algo-1, epoch=3, batch=3000 train binary_classification_cross_entropy <loss>=0.05542516048397075\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:48:08 INFO 139841683838784] Epoch[3] Batch [4000]#011Speed: 112910.28 samples/sec#011binary_classification_accuracy=0.986884#011binary_classification_cross_entropy=0.055523\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:48:08 INFO 139841683838784] #quality_metric: host=algo-1, epoch=3, batch=4000 train binary_classification_accuracy <score>=0.9868840289927518\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:48:08 INFO 139841683838784] #quality_metric: host=algo-1, epoch=3, batch=4000 train binary_classification_cross_entropy <loss>=0.05552304713662283\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:48:17 INFO 139841683838784] Epoch[3] Batch [5000]#011Speed: 112679.27 samples/sec#011binary_classification_accuracy=0.986902#011binary_classification_cross_entropy=0.055482\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:48:17 INFO 139841683838784] #quality_metric: host=algo-1, epoch=3, batch=5000 train binary_classification_accuracy <score>=0.9869022195560888\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:48:17 INFO 139841683838784] #quality_metric: host=algo-1, epoch=3, batch=5000 train binary_classification_cross_entropy <loss>=0.0554822155880561\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:48:25 INFO 139841683838784] Epoch[3] Batch [6000]#011Speed: 112994.67 samples/sec#011binary_classification_accuracy=0.986846#011binary_classification_cross_entropy=0.055610\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:48:25 INFO 139841683838784] #quality_metric: host=algo-1, epoch=3, batch=6000 train binary_classification_accuracy <score>=0.9868456923846025\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:48:25 INFO 139841683838784] #quality_metric: host=algo-1, epoch=3, batch=6000 train binary_classification_cross_entropy <loss>=0.05561032105477487\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:48:34 INFO 139841683838784] Epoch[3] Batch [7000]#011Speed: 113627.67 samples/sec#011binary_classification_accuracy=0.986851#011binary_classification_cross_entropy=0.055587\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:48:34 INFO 139841683838784] #quality_metric: host=algo-1, epoch=3, batch=7000 train binary_classification_accuracy <score>=0.9868507356091987\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:48:34 INFO 139841683838784] #quality_metric: host=algo-1, epoch=3, batch=7000 train binary_classification_cross_entropy <loss>=0.05558694935648667\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:48:43 INFO 139841683838784] Epoch[3] Batch [8000]#011Speed: 113335.70 samples/sec#011binary_classification_accuracy=0.986883#011binary_classification_cross_entropy=0.055458\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:48:43 INFO 139841683838784] #quality_metric: host=algo-1, epoch=3, batch=8000 train binary_classification_accuracy <score>=0.9868828896387951\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:48:43 INFO 139841683838784] #quality_metric: host=algo-1, epoch=3, batch=8000 train binary_classification_cross_entropy <loss>=0.0554582697183337\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:48:52 INFO 139841683838784] Epoch[3] Batch [9000]#011Speed: 114018.77 samples/sec#011binary_classification_accuracy=0.986881#011binary_classification_cross_entropy=0.055484\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:48:52 INFO 139841683838784] #quality_metric: host=algo-1, epoch=3, batch=9000 train binary_classification_accuracy <score>=0.9868809021219864\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:48:52 INFO 139841683838784] #quality_metric: host=algo-1, epoch=3, batch=9000 train binary_classification_cross_entropy <loss>=0.05548381249637898\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:49:01 INFO 139841683838784] Epoch[3] Batch [10000]#011Speed: 112729.93 samples/sec#011binary_classification_accuracy=0.986903#011binary_classification_cross_entropy=0.055432\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:49:01 INFO 139841683838784] #quality_metric: host=algo-1, epoch=3, batch=10000 train binary_classification_accuracy <score>=0.9869026097390261\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:49:01 INFO 139841683838784] #quality_metric: host=algo-1, epoch=3, batch=10000 train binary_classification_cross_entropy <loss>=0.05543203968082043\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:49:09 INFO 139841683838784] Epoch[3] Batch [11000]#011Speed: 113382.14 samples/sec#011binary_classification_accuracy=0.986893#011binary_classification_cross_entropy=0.055458\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:49:09 INFO 139841683838784] #quality_metric: host=algo-1, epoch=3, batch=11000 train binary_classification_accuracy <score>=0.9868934642305245\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:49:09 INFO 139841683838784] #quality_metric: host=algo-1, epoch=3, batch=11000 train binary_classification_cross_entropy <loss>=0.055457925870541866\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:49:18 INFO 139841683838784] Epoch[3] Batch [12000]#011Speed: 113325.15 samples/sec#011binary_classification_accuracy=0.986891#011binary_classification_cross_entropy=0.055440\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:49:18 INFO 139841683838784] #quality_metric: host=algo-1, epoch=3, batch=12000 train binary_classification_accuracy <score>=0.9868908424297975\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:49:18 INFO 139841683838784] #quality_metric: host=algo-1, epoch=3, batch=12000 train binary_classification_cross_entropy <loss>=0.05543986768812331\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:49:27 INFO 139841683838784] Epoch[3] Batch [13000]#011Speed: 113573.12 samples/sec#011binary_classification_accuracy=0.986888#011binary_classification_cross_entropy=0.055440\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:49:27 INFO 139841683838784] #quality_metric: host=algo-1, epoch=3, batch=13000 train binary_classification_accuracy <score>=0.986888393200523\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:49:27 INFO 139841683838784] #quality_metric: host=algo-1, epoch=3, batch=13000 train binary_classification_cross_entropy <loss>=0.05543973242386553\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:49:36 INFO 139841683838784] Epoch[3] Batch [14000]#011Speed: 112770.86 samples/sec#011binary_classification_accuracy=0.986897#011binary_classification_cross_entropy=0.055397\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:49:36 INFO 139841683838784] #quality_metric: host=algo-1, epoch=3, batch=14000 train binary_classification_accuracy <score>=0.9868967930862081\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:49:36 INFO 139841683838784] #quality_metric: host=algo-1, epoch=3, batch=14000 train binary_classification_cross_entropy <loss>=0.0553969643416213\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:49:45 INFO 139841683838784] Epoch[3] Batch [15000]#011Speed: 113356.69 samples/sec#011binary_classification_accuracy=0.986902#011binary_classification_cross_entropy=0.055386\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:49:45 INFO 139841683838784] #quality_metric: host=algo-1, epoch=3, batch=15000 train binary_classification_accuracy <score>=0.9869018732084528\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:49:45 INFO 139841683838784] #quality_metric: host=algo-1, epoch=3, batch=15000 train binary_classification_cross_entropy <loss>=0.0553863619027571\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:49:48 INFO 139841683838784] Epoch[3] Train-binary_classification_accuracy=0.986911\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:49:48 INFO 139841683838784] Epoch[3] Train-binary_classification_cross_entropy=0.055354\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:49:48 INFO 139841683838784] Epoch[3] Time cost=136.079\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:49:48 INFO 139841683838784] #quality_metric: host=algo-1, epoch=3, train binary_classification_accuracy <score>=0.9869114935064935\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:49:48 INFO 139841683838784] #quality_metric: host=algo-1, epoch=3, train binary_classification_cross_entropy <loss>=0.05535383072159507\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1742237252.6994376, \"EndTime\": 1742237388.7832506, \"Dimensions\": {\"Algorithm\": \"ipinsights\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 136083.38046073914, \"count\": 1, \"min\": 136083.38046073914, \"max\": 136083.38046073914}}}\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:49:48 INFO 139841683838784] #progress_metric: host=algo-1, completed 80.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1742237252.6998434, \"EndTime\": 1742237388.783453, \"Dimensions\": {\"Algorithm\": \"ipinsights\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 61582556.0, \"count\": 1, \"min\": 61582556, \"max\": 61582556}, \"Total Batches Seen\": {\"sum\": 61600.0, \"count\": 1, \"min\": 61600, \"max\": 61600}, \"Max Records Seen Between Resets\": {\"sum\": 15395639.0, \"count\": 1, \"min\": 15395639, \"max\": 15395639}, \"Max Batches Seen Between Resets\": {\"sum\": 15400.0, \"count\": 1, \"min\": 15400, \"max\": 15400}, \"Reset Count\": {\"sum\": 8.0, \"count\": 1, \"min\": 8, \"max\": 8}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:49:48 INFO 139841683838784] #throughput_metric: host=algo-1, train throughput=113133.58644395438 records/second\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:49:48 WARNING 139841683838784] Already bound, ignoring bind()\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:49:48 WARNING 139841683838784] optimizer already initialized, ignoring...\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:49:48 INFO 139841683838784] #quality_metric: host=algo-1, epoch=4, batch=0 train binary_classification_accuracy <score>=0.984\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:49:48 INFO 139841683838784] #quality_metric: host=algo-1, epoch=4, batch=0 train binary_classification_cross_entropy <loss>=0.06668238830566406\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:49:57 INFO 139841683838784] Epoch[4] Batch [1000]#011Speed: 114650.75 samples/sec#011binary_classification_accuracy=0.986932#011binary_classification_cross_entropy=0.054502\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:49:57 INFO 139841683838784] #quality_metric: host=algo-1, epoch=4, batch=1000 train binary_classification_accuracy <score>=0.9869320679320679\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:49:57 INFO 139841683838784] #quality_metric: host=algo-1, epoch=4, batch=1000 train binary_classification_cross_entropy <loss>=0.05450151819615931\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:50:06 INFO 139841683838784] Epoch[4] Batch [2000]#011Speed: 115029.25 samples/sec#011binary_classification_accuracy=0.986913#011binary_classification_cross_entropy=0.054822\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:50:06 INFO 139841683838784] #quality_metric: host=algo-1, epoch=4, batch=2000 train binary_classification_accuracy <score>=0.986912543728136\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:50:06 INFO 139841683838784] #quality_metric: host=algo-1, epoch=4, batch=2000 train binary_classification_cross_entropy <loss>=0.05482244096476695\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:50:14 INFO 139841683838784] Epoch[4] Batch [3000]#011Speed: 115304.44 samples/sec#011binary_classification_accuracy=0.987050#011binary_classification_cross_entropy=0.054482\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:50:14 INFO 139841683838784] #quality_metric: host=algo-1, epoch=4, batch=3000 train binary_classification_accuracy <score>=0.987049983338887\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:50:14 INFO 139841683838784] #quality_metric: host=algo-1, epoch=4, batch=3000 train binary_classification_cross_entropy <loss>=0.054482397373737154\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:50:23 INFO 139841683838784] Epoch[4] Batch [4000]#011Speed: 114898.25 samples/sec#011binary_classification_accuracy=0.987003#011binary_classification_cross_entropy=0.054694\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:50:23 INFO 139841683838784] #quality_metric: host=algo-1, epoch=4, batch=4000 train binary_classification_accuracy <score>=0.9870034991252187\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:50:23 INFO 139841683838784] #quality_metric: host=algo-1, epoch=4, batch=4000 train binary_classification_cross_entropy <loss>=0.05469408684806566\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:50:32 INFO 139841683838784] Epoch[4] Batch [5000]#011Speed: 115611.00 samples/sec#011binary_classification_accuracy=0.987000#011binary_classification_cross_entropy=0.054682\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:50:32 INFO 139841683838784] #quality_metric: host=algo-1, epoch=4, batch=5000 train binary_classification_accuracy <score>=0.987\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:50:32 INFO 139841683838784] #quality_metric: host=algo-1, epoch=4, batch=5000 train binary_classification_cross_entropy <loss>=0.0546815485322125\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:50:40 INFO 139841683838784] Epoch[4] Batch [6000]#011Speed: 115603.44 samples/sec#011binary_classification_accuracy=0.986960#011binary_classification_cross_entropy=0.054754\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:50:40 INFO 139841683838784] #quality_metric: host=algo-1, epoch=4, batch=6000 train binary_classification_accuracy <score>=0.9869600066655557\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:50:40 INFO 139841683838784] #quality_metric: host=algo-1, epoch=4, batch=6000 train binary_classification_cross_entropy <loss>=0.05475420568720775\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:50:49 INFO 139841683838784] Epoch[4] Batch [7000]#011Speed: 115877.93 samples/sec#011binary_classification_accuracy=0.986957#011binary_classification_cross_entropy=0.054781\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:50:49 INFO 139841683838784] #quality_metric: host=algo-1, epoch=4, batch=7000 train binary_classification_accuracy <score>=0.9869574346521925\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:50:49 INFO 139841683838784] #quality_metric: host=algo-1, epoch=4, batch=7000 train binary_classification_cross_entropy <loss>=0.05478084059814575\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:50:58 INFO 139841683838784] Epoch[4] Batch [8000]#011Speed: 115051.13 samples/sec#011binary_classification_accuracy=0.986956#011binary_classification_cross_entropy=0.054688\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:50:58 INFO 139841683838784] #quality_metric: host=algo-1, epoch=4, batch=8000 train binary_classification_accuracy <score>=0.9869557555305587\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:50:58 INFO 139841683838784] #quality_metric: host=algo-1, epoch=4, batch=8000 train binary_classification_cross_entropy <loss>=0.05468822345893363\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:51:06 INFO 139841683838784] Epoch[4] Batch [9000]#011Speed: 114714.14 samples/sec#011binary_classification_accuracy=0.986943#011binary_classification_cross_entropy=0.054751\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:51:06 INFO 139841683838784] #quality_metric: host=algo-1, epoch=4, batch=9000 train binary_classification_accuracy <score>=0.9869431174313965\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:51:06 INFO 139841683838784] #quality_metric: host=algo-1, epoch=4, batch=9000 train binary_classification_cross_entropy <loss>=0.05475111102475125\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:51:15 INFO 139841683838784] Epoch[4] Batch [10000]#011Speed: 115631.76 samples/sec#011binary_classification_accuracy=0.986966#011binary_classification_cross_entropy=0.054714\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:51:15 INFO 139841683838784] #quality_metric: host=algo-1, epoch=4, batch=10000 train binary_classification_accuracy <score>=0.98696600339966\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:51:15 INFO 139841683838784] #quality_metric: host=algo-1, epoch=4, batch=10000 train binary_classification_cross_entropy <loss>=0.054713566525961536\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:51:24 INFO 139841683838784] Epoch[4] Batch [11000]#011Speed: 114212.40 samples/sec#011binary_classification_accuracy=0.986973#011binary_classification_cross_entropy=0.054716\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:51:24 INFO 139841683838784] #quality_metric: host=algo-1, epoch=4, batch=11000 train binary_classification_accuracy <score>=0.9869729115534951\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:51:24 INFO 139841683838784] #quality_metric: host=algo-1, epoch=4, batch=11000 train binary_classification_cross_entropy <loss>=0.054716416021984564\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:51:33 INFO 139841683838784] Epoch[4] Batch [12000]#011Speed: 115250.89 samples/sec#011binary_classification_accuracy=0.986986#011binary_classification_cross_entropy=0.054695\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:51:33 INFO 139841683838784] #quality_metric: host=algo-1, epoch=4, batch=12000 train binary_classification_accuracy <score>=0.9869857511874011\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:51:33 INFO 139841683838784] #quality_metric: host=algo-1, epoch=4, batch=12000 train binary_classification_cross_entropy <loss>=0.05469485614828423\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:51:41 INFO 139841683838784] Epoch[4] Batch [13000]#011Speed: 115892.80 samples/sec#011binary_classification_accuracy=0.986977#011binary_classification_cross_entropy=0.054700\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:51:41 INFO 139841683838784] #quality_metric: host=algo-1, epoch=4, batch=13000 train binary_classification_accuracy <score>=0.9869768479347742\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:51:41 INFO 139841683838784] #quality_metric: host=algo-1, epoch=4, batch=13000 train binary_classification_cross_entropy <loss>=0.05469982590494537\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:51:50 INFO 139841683838784] Epoch[4] Batch [14000]#011Speed: 115570.70 samples/sec#011binary_classification_accuracy=0.986972#011binary_classification_cross_entropy=0.054696\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:51:50 INFO 139841683838784] #quality_metric: host=algo-1, epoch=4, batch=14000 train binary_classification_accuracy <score>=0.9869715020355689\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:51:50 INFO 139841683838784] #quality_metric: host=algo-1, epoch=4, batch=14000 train binary_classification_cross_entropy <loss>=0.054696464839777546\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:51:58 INFO 139841683838784] Epoch[4] Batch [15000]#011Speed: 115181.23 samples/sec#011binary_classification_accuracy=0.986966#011binary_classification_cross_entropy=0.054686\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:51:58 INFO 139841683838784] #quality_metric: host=algo-1, epoch=4, batch=15000 train binary_classification_accuracy <score>=0.9869655356309579\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:51:58 INFO 139841683838784] #quality_metric: host=algo-1, epoch=4, batch=15000 train binary_classification_cross_entropy <loss>=0.05468557964945688\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:52:02 INFO 139841683838784] Epoch[4] Train-binary_classification_accuracy=0.986971\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:52:02 INFO 139841683838784] Epoch[4] Train-binary_classification_cross_entropy=0.054674\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:52:02 INFO 139841683838784] Epoch[4] Time cost=133.677\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:52:02 INFO 139841683838784] #quality_metric: host=algo-1, epoch=4, train binary_classification_accuracy <score>=0.9869711688311689\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:52:02 INFO 139841683838784] #quality_metric: host=algo-1, epoch=4, train binary_classification_cross_entropy <loss>=0.054673620267162076\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1742237388.7833114, \"EndTime\": 1742237522.4639995, \"Dimensions\": {\"Algorithm\": \"ipinsights\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 133680.30714988708, \"count\": 1, \"min\": 133680.30714988708, \"max\": 133680.30714988708}}}\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:52:02 INFO 139841683838784] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1742237388.7836597, \"EndTime\": 1742237522.4642494, \"Dimensions\": {\"Algorithm\": \"ipinsights\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 76978195.0, \"count\": 1, \"min\": 76978195, \"max\": 76978195}, \"Total Batches Seen\": {\"sum\": 77000.0, \"count\": 1, \"min\": 77000, \"max\": 77000}, \"Max Records Seen Between Resets\": {\"sum\": 15395639.0, \"count\": 1, \"min\": 15395639, \"max\": 15395639}, \"Max Batches Seen Between Resets\": {\"sum\": 15400.0, \"count\": 1, \"min\": 15400, \"max\": 15400}, \"Reset Count\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:52:02 INFO 139841683838784] #throughput_metric: host=algo-1, train throughput=115167.24351080398 records/second\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:52:02 WARNING 139841683838784] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1742237522.4640834, \"EndTime\": 1742237522.4647837, \"Dimensions\": {\"Algorithm\": \"ipinsights\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 0.22363662719726562, \"count\": 1, \"min\": 0.22363662719726562, \"max\": 0.22363662719726562}}}\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:52:02 INFO 139841683838784] Saved checkpoint to \"/tmp/tmpoo_syp9m/state-0001.params\"\u001b[0m\n",
      "\u001b[34m[03/17/2025 18:52:02 INFO 139841683838784] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1742237522.4648535, \"EndTime\": 1742237522.4997385, \"Dimensions\": {\"Algorithm\": \"ipinsights\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 41.36323928833008, \"count\": 1, \"min\": 41.36323928833008, \"max\": 41.36323928833008}, \"totaltime\": {\"sum\": 673552.1554946899, \"count\": 1, \"min\": 673552.1554946899, \"max\": 673552.1554946899}}}\u001b[0m\n",
      "\n",
      "2025-03-17 18:52:25 Uploading - Uploading generated training model\n",
      "2025-03-17 18:52:33 Completed - Training job completed\n",
      "Training seconds: 884\n",
      "Billable seconds: 884\n"
     ]
    }
   ],
   "source": [
    "# Set up the estimator with training job configuration\n",
    "ip_insights = sagemaker.estimator.Estimator(\n",
    "    image,\n",
    "    execution_role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m4.2xlarge\",\n",
    "    output_path=f\"s3://{bucket}/{prefix}/output\",\n",
    "    sagemaker_session=sagemaker.Session(),\n",
    ")\n",
    "\n",
    "# Configure algorithm-specific hyperparameters\n",
    "ip_insights.set_hyperparameters(\n",
    "    num_entity_vectors=\"20000\",\n",
    "    random_negative_sampling_rate=\"5\",\n",
    "    vector_dim=\"128\",\n",
    "    mini_batch_size=\"1000\",\n",
    "    epochs=\"5\",\n",
    "    learning_rate=\"0.01\",\n",
    ")\n",
    "\n",
    "# Start the training job (should take about ~1.5 minute / epoch to complete)\n",
    "ip_insights.fit(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see the message\n",
    "\n",
    "    > Completed - Training job completed\n",
    "\n",
    "at the bottom of the output logs then that means training successfully completed and the output of the SageMaker IP Insights model was stored in the specified output path. You can also view information about and the status of a training job using the AWS SageMaker console. Just click on the \"Jobs\" tab and select training job matching the training job name, below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job name: ipinsights-2025-03-17-18-37-14-430\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training job name: {ip_insights.latest_training_job.job_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "-----\n",
    "\n",
    "Now that we have trained a SageMaker IP Insights model, we can deploy the model to an endpoint to start performing inference on data. In this case, that means providing it a `<user, IP address>` pair and predicting their compatability scores.\n",
    "\n",
    "We can create an inference endpoint using the SageMaker Python SDK `deploy()`function from the job we defined above. We specify the instance type where inference will be performed, as well as the initial number of instnaces to spin up. We recommend using the `ml.m5` instance as it provides the most memory at the lowest cost. Verify how large your model is in S3 and pick the instance type with the appropriate amount of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03/17/25 18:55:20] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating model with name: ipinsights-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-03-17-18-55-20-784           <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#4094\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4094</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03/17/25 18:55:20]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating model with name: ipinsights-\u001b[1;36m2025\u001b[0m-03-17-18-55-20-784           \u001b]8;id=389401;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=187200;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#4094\u001b\\\u001b[2m4094\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03/17/25 18:55:21] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint-config with name ipinsights-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-03-17-18-55-20-784  <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#5937\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5937</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03/17/25 18:55:21]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint-config with name ipinsights-\u001b[1;36m2025\u001b[0m-03-17-18-55-20-784  \u001b]8;id=503294;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=729685;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#5937\u001b\\\u001b[2m5937\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint with name ipinsights-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-03-17-18-55-20-784         <a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#4759\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4759</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint with name ipinsights-\u001b[1;36m2025\u001b[0m-03-17-18-55-20-784         \u001b]8;id=43839;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=145972;file:///home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/session.py#4759\u001b\\\u001b[2m4759\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "predictor = ip_insights.deploy(initial_instance_count=1, instance_type=\"ml.m5.xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you now have a SageMaker IP Insights inference endpoint! You could start integrating this endpoint with your production services to start querying incoming requests for abnormal behavior. \n",
    "\n",
    "You can confirm the endpoint configuration and status by navigating to the \"Endpoints\" tab in the AWS SageMaker console and selecting the endpoint matching the endpoint name below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Endpoint name: {predictor.endpoint}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Serialization/Deserialization\n",
    "We can pass data in a variety of formats to our inference endpoint. In this example, we will pass CSV-formmated data. Other available formats are JSON-formated and JSON Lines-formatted. We make use of the SageMaker Python SDK utilities: `csv_serializer` and `json_deserializer` when configuring the inference endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.base_predictor import csv_serializer, json_deserializer\n",
    "\n",
    "predictor.serializer = csv_serializer\n",
    "predictor.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the predictor is configured, it is as easy as passing in a matrix of inference data.\n",
    "We can take a few samples from the simulated dataset above, so we can see what the output looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_data = [(data[0], data[1]) for data in train_df[:5].values]\n",
    "predictor.predict(\n",
    "    inference_data, initial_args={\"ContentType\": \"text/csv\", \"Accept\": \"application/json\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the predictor will only output the `dot_product` between the learned IP address and the online resource (in this case, the user ID). The dot product summarizes the compatibility between the IP address and online resource. The larger the value, the more the algorithm thinks the IP address is likely to be used by the user. This compatability score is sufficient for most applications, as we can define a threshold for what we constitute as an anomalous score.\n",
    "\n",
    "However, more advanced users may want to inspect the learned embeddings and use them in further applications. We can configure the predictor to provide the learned embeddings by specifing the `verbose=True` parameter to the Accept heading. You should see that each 'prediction' object contains three keys: `ip_embedding`, `entity_embedding`, and `dot_product`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictor.predict(\n",
    "    inference_data,\n",
    "    initial_args={\"ContentType\": \"text/csv\", \"Accept\": \"application/json; verbose=True\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Anomaly Scores\n",
    "----\n",
    "The `dot_product` output of the model provides a good measure of how compatible an IP address and online resource are. However, the range of the dot_product is unbounded. This means to be able to consider an event as anomolous we need to define a threshold. Such that when we score an event, if the dot_product is above the threshold we can flag the behavior as anomolous.However, picking a threshold can be more of an art, and a good threshold depends on the specifics of your problem and dataset. \n",
    "\n",
    "In the following section, we show how to pick a simple threshold by comparing the score distributions between known normal and malicious traffic:\n",
    "1. We construct a test set of 'Normal' traffic;\n",
    "2. Inject 'Malicious' traffic into the dataset;\n",
    "3. Plot the distribution of dot_product scores for the model on 'Normal' trafic and the 'Malicious' traffic.\n",
    "3. Select a threshold value which separates the normal distribution from the malicious traffic threshold. This value is based on your false-positive tolerance.\n",
    "\n",
    "### 1. Construct 'Normal' Traffic Dataset\n",
    "\n",
    "We previously [created a test set](#3.-Create-training-and-test-dataset) from our simulated Apache access logs dataset. We use this test dataset as the 'Normal' traffic in the test case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Inject Malicious Traffic\n",
    "If we had a dataset with enough real malicious activity, we would use that to determine a good threshold. Those are hard to come by. So instead, we simulate malicious web traffic that mimics a realistic attack scenario. \n",
    "\n",
    "We take a set of user accounts from the test set and randomly generate IP addresses. The users should not have used these IP addresses during training. This simulates an attacker logging in to a user account without knowledge of their IP history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from generate_data import draw_ip\n",
    "\n",
    "\n",
    "def score_ip_insights(predictor, df):\n",
    "    def get_score(result):\n",
    "        \"\"\"Return the negative to the dot product of the predictions from the model.\"\"\"\n",
    "        return [-prediction[\"dot_product\"] for prediction in result[\"predictions\"]]\n",
    "\n",
    "    df = df[[\"user\", \"ip_address\"]]\n",
    "    result = predictor.predict(df.values)\n",
    "    return get_score(result)\n",
    "\n",
    "\n",
    "def create_test_case(train_df, test_df, num_samples, attack_freq):\n",
    "    \"\"\"Creates a test case from provided train and test data frames.\n",
    "\n",
    "    This generates test case for accounts that are both in training and testing data sets.\n",
    "\n",
    "    :param train_df: (panda.DataFrame with columns ['user', 'ip_address']) training DataFrame\n",
    "    :param test_df: (panda.DataFrame with columns ['user', 'ip_address']) testing DataFrame\n",
    "    :param num_samples: (int) number of test samples to use\n",
    "    :param attack_freq: (float) the ratio of negative_samples:positive_samples to generate for test case\n",
    "    :return: DataFrame with both good and bad traffic, with labels\n",
    "    \"\"\"\n",
    "    # Get all possible accounts. The IP Insights model can only make predictions on users it has seen in training\n",
    "    # Therefore, filter the test dataset for unseen accounts, as their results will not mean anything.\n",
    "    valid_accounts = set(train_df[\"user\"])\n",
    "    valid_test_df = test_df[test_df[\"user\"].isin(valid_accounts)]\n",
    "\n",
    "    good_traffic = valid_test_df.sample(num_samples, replace=False)\n",
    "    good_traffic = good_traffic[[\"user\", \"ip_address\"]]\n",
    "    good_traffic[\"label\"] = 0\n",
    "\n",
    "    # Generate malicious traffic\n",
    "    num_bad_traffic = int(num_samples * attack_freq)\n",
    "    bad_traffic_accounts = np.random.choice(\n",
    "        list(valid_accounts), size=num_bad_traffic, replace=True\n",
    "    )\n",
    "    bad_traffic_ips = [draw_ip() for i in range(num_bad_traffic)]\n",
    "    bad_traffic = pd.DataFrame({\"user\": bad_traffic_accounts, \"ip_address\": bad_traffic_ips})\n",
    "    bad_traffic[\"label\"] = 1\n",
    "\n",
    "    # All traffic labels are: 0 for good traffic; 1 for bad traffic.\n",
    "    all_traffic = pd.concat([good_traffic, bad_traffic])\n",
    "\n",
    "    return all_traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 100000\n",
    "test_case = create_test_case(train_df, test_df, num_samples=NUM_SAMPLES, attack_freq=1)\n",
    "test_case.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case_scores = score_ip_insights(predictor, test_case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Plot Distribution\n",
    "\n",
    "Now, we plot the distribution of scores. Looking at this distribution will inform us on where we can set a good threshold, based on our risk tolerance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n, x = np.histogram(test_case_scores[:NUM_SAMPLES], bins=100, density=True)\n",
    "plt.plot(x[1:], n)\n",
    "\n",
    "n, x = np.histogram(test_case_scores[NUM_SAMPLES:], bins=100, density=True)\n",
    "plt.plot(x[1:], n)\n",
    "\n",
    "plt.legend([\"Normal\", \"Random IP\"])\n",
    "plt.xlabel(\"IP Insights Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Selecting a Good Threshold\n",
    "\n",
    "As we see in the figure above, there is a clear separation between normal traffic and random traffic. \n",
    "We could select a threshold depending on the application.\n",
    "\n",
    "- If we were working with low impact decisions, such as whether to ask for another factor or authentication during login, we could use a `threshold = 0.0`. This would result in catching more true-positives, at the cost of more false-positives. \n",
    "\n",
    "- If our decision system were more sensitive to false positives, we could choose a larger threshold, such as `threshold = 10.0`. That way if we were sending the flagged cases to manual investigation, we would have a higher confidence that the acitivty was suspicious. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.0\n",
    "\n",
    "flagged_cases = test_case[np.array(test_case_scores) > threshold]\n",
    "\n",
    "num_flagged_cases = len(flagged_cases)\n",
    "num_true_positives = len(flagged_cases[flagged_cases[\"label\"] == 1])\n",
    "num_false_positives = len(flagged_cases[flagged_cases[\"label\"] == 0])\n",
    "num_all_positives = len(test_case.loc[test_case[\"label\"] == 1])\n",
    "\n",
    "print(f\"When threshold is set to: {threshold}\")\n",
    "print(f\"Total of {num_flagged_cases} flagged cases\")\n",
    "print(f\"Total of {num_true_positives} flagged cases are true positives\")\n",
    "print(f\"True Positive Rate: {num_true_positives / float(num_flagged_cases)}\")\n",
    "print(f\"Recall: {num_true_positives / float(num_all_positives)}\")\n",
    "print(f\"Precision: {num_true_positives / float(num_flagged_cases)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epilogue\n",
    "----\n",
    "\n",
    "In this notebook, we have showed how to configure the basic training, deployment, and usage of the Amazon SageMaker IP Insights algorithm. All SageMaker algorithms come with support for two additional services that make optimizing and using the algorithm that much easier: Automatic Model Tuning and Batch Transform service. \n",
    "\n",
    "\n",
    "### Amazon SageMaker Automatic Model Tuning\n",
    "The results above were based on using the default hyperparameters of the SageMaker IP Insights algorithm. If we wanted to improve the model's performance even more, we can use [Amazon SageMaker Automatic Model Tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html) to automate the process of finding the hyperparameters. \n",
    "\n",
    "#### Validation Dataset\n",
    "Previously, we separated our dataset into a training and test set to validate the performance of a single IP Insights model. However, when we do model tuning, we train many IP Insights models in parallel. If we were to use the same test dataset to select the best model, we bias our model selection such that we don't know if we selected the best model in general, or just the best model for that particular dateaset. \n",
    "\n",
    "Therefore, we need to separate our test set into a validation dataset and a test dataset. The validation dataset is used for model selection. Then once we pick the model with the best performance, we evaluate it the winner on a test set just as before. \n",
    "\n",
    "#### Validation Metrics\n",
    "For SageMaker Automatic Model Tuning to work, we need an objective metric which determines the performance of the model we want to optimize. Because SageMaker IP Insights is an usupervised algorithm, we do not have a clearly defined metric for performance (such as percentage of fraudulent events discovered). \n",
    "\n",
    "We allow the user to provide a validation set of sample data (same format as training data bove) through the `validation` channel. We then fix the negative sampling strategy to use `random_negative_sampling_rate=1` and `shuffled_negative_sampling_rate=0` and generate a validation dataset by assigning corresponding labels to the real and simulated data. We then calculate the model's `descriminator_auc` metric. We do this by taking the model's predicted labels and the 'true' simulated labels and compute the Area Under ROC Curve (AUC) on the model's performance.\n",
    "\n",
    "We set up the `HyperParameterTuner` to maximize the `discriminator_auc` on the validation dataset. We also need to set the search space for the hyperparameters. We give recommended ranges for the hyperparmaeters in the [Amazon SageMaker IP Insights (Hyperparameters)](https://docs.aws.amazon.com/sagemaker/latest/dg/ip-insights-hyperparameters.html) documentation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"timestamp\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test set we constructed above spans 3 days. We reserve the first day as the validation set and the subsequent two days for the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_partition = (\n",
    "    datetime(2018, 11, 13, tzinfo=pytz.FixedOffset(0))\n",
    "    if num_time_zones > 1\n",
    "    else datetime(2018, 11, 13)\n",
    ")\n",
    "\n",
    "validation_df = test_df[test_df[\"timestamp\"] < time_partition]\n",
    "test_df = test_df[test_df[\"timestamp\"] >= time_partition]\n",
    "\n",
    "valid_data = validation_df.to_csv(index=False, header=False, columns=[\"user\", \"ip_address\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then upload the validation data to S3 and specify it as the validation channel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload data to S3 key\n",
    "validation_data_file = \"valid.csv\"\n",
    "key = os.path.join(prefix, \"validation\", validation_data_file)\n",
    "boto3.resource(\"s3\").Bucket(bucket).Object(key).put(Body=valid_data)\n",
    "s3_valid_data = f\"s3://{bucket}/{key}\"\n",
    "\n",
    "print(f\"Validation data has been uploaded to: {s3_valid_data}\")\n",
    "\n",
    "# Configure SageMaker IP Insights Input Channels\n",
    "input_data = {\"train\": s3_train_data, \"validation\": s3_valid_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import HyperparameterTuner, IntegerParameter\n",
    "\n",
    "# Configure HyperparameterTuner\n",
    "ip_insights_tuner = HyperparameterTuner(\n",
    "    estimator=ip_insights,  # previously-configured Estimator object\n",
    "    objective_metric_name=\"validation:discriminator_auc\",\n",
    "    hyperparameter_ranges={\"vector_dim\": IntegerParameter(64, 1024)},\n",
    "    max_jobs=4,\n",
    "    max_parallel_jobs=2,\n",
    ")\n",
    "\n",
    "# Start hyperparameter tuning job\n",
    "ip_insights_tuner.fit(input_data, include_cls_metadata=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for all the jobs to finish\n",
    "ip_insights_tuner.wait()\n",
    "\n",
    "# Visualize training job results\n",
    "ip_insights_tuner.analytics().dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy best model\n",
    "tuned_predictor = ip_insights_tuner.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    serializer=csv_serializer,\n",
    "    deserializer=json_deserializer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction against the SageMaker endpoint\n",
    "tuned_predictor.predict(\n",
    "    inference_data, initial_args={\"ContentType\": \"text/csv\", \"Accept\": \"application/json\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should have the best performing model from the training job! Now we can determine thresholds and make predictions just like we did with the inference endpoint [above](#Inference)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Transform\n",
    "Let's say we want to score all of the login events at the end of the day and aggregate flagged cases for investigators to look at in the morning. If we store the daily login events in S3, we can use IP Insights with [Amazon SageMaker Batch Transform](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-batch.html) to run inference and store the IP Insights scores back in S3 for future analysis.\n",
    "\n",
    "Below, we take the training job from before and evaluate it on the validation data we put in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = ip_insights.transformer(instance_count=1, instance_type=\"ml.m4.xlarge\")\n",
    "\n",
    "transformer.transform(s3_valid_data, content_type=\"text/csv\", split_type=\"Line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for Transform Job to finish\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Batch Transform output is at: {transformer.output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop and Delete the Endpoint\n",
    "If you are done with this model, then we should delete the endpoint before we close the notebook. Or else you will continue to pay for the endpoint while it is running. \n",
    "\n",
    "To do so execute the cell below. Alternately, you can navigate to the \"Endpoints\" tab in the SageMaker console, select the endpoint with the name stored in the variable endpoint_name, and select \"Delete\" from the \"Actions\" dropdown menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_predictor.delete_model()\n",
    "tuned_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook CI Test Results\n",
    "\n",
    "This notebook was tested in multiple regions. The test results are as follows, except for us-west-2 which is shown at the top of the notebook.\n",
    "\n",
    "![This us-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-1/introduction_to_amazon_algorithms|ipinsights_login|ipinsights-tutorial.ipynb)\n",
    "\n",
    "![This us-east-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-east-2/introduction_to_amazon_algorithms|ipinsights_login|ipinsights-tutorial.ipynb)\n",
    "\n",
    "![This us-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/us-west-1/introduction_to_amazon_algorithms|ipinsights_login|ipinsights-tutorial.ipynb)\n",
    "\n",
    "![This ca-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ca-central-1/introduction_to_amazon_algorithms|ipinsights_login|ipinsights-tutorial.ipynb)\n",
    "\n",
    "![This sa-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/sa-east-1/introduction_to_amazon_algorithms|ipinsights_login|ipinsights-tutorial.ipynb)\n",
    "\n",
    "![This eu-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-1/introduction_to_amazon_algorithms|ipinsights_login|ipinsights-tutorial.ipynb)\n",
    "\n",
    "![This eu-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-2/introduction_to_amazon_algorithms|ipinsights_login|ipinsights-tutorial.ipynb)\n",
    "\n",
    "![This eu-west-3 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-west-3/introduction_to_amazon_algorithms|ipinsights_login|ipinsights-tutorial.ipynb)\n",
    "\n",
    "![This eu-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-central-1/introduction_to_amazon_algorithms|ipinsights_login|ipinsights-tutorial.ipynb)\n",
    "\n",
    "![This eu-north-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/eu-north-1/introduction_to_amazon_algorithms|ipinsights_login|ipinsights-tutorial.ipynb)\n",
    "\n",
    "![This ap-southeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-1/introduction_to_amazon_algorithms|ipinsights_login|ipinsights-tutorial.ipynb)\n",
    "\n",
    "![This ap-southeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-southeast-2/introduction_to_amazon_algorithms|ipinsights_login|ipinsights-tutorial.ipynb)\n",
    "\n",
    "![This ap-northeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-1/introduction_to_amazon_algorithms|ipinsights_login|ipinsights-tutorial.ipynb)\n",
    "\n",
    "![This ap-northeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-northeast-2/introduction_to_amazon_algorithms|ipinsights_login|ipinsights-tutorial.ipynb)\n",
    "\n",
    "![This ap-south-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://prod.us-west-2.tcx-beacon.docs.aws.dev/sagemaker-nb/ap-south-1/introduction_to_amazon_algorithms|ipinsights_login|ipinsights-tutorial.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
